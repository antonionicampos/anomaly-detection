{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pressed-dining",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import Dataset\n",
    "from datetime import datetime\n",
    "from model import Autoencoder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "harmful-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs=20):\n",
    "    \n",
    "    print('starting model training...')\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"training on {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "    model.to(device)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        training_loss, running_loss = 0.0, 0.0\n",
    "        \n",
    "        # Iterando sobre o dataset\n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            X = data['X'].to(device)\n",
    "            \n",
    "            # Zero Grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            output = model(X)\n",
    "\n",
    "            # Loss Function\n",
    "            loss = criterion(output, X)\n",
    "\n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "            running_loss += loss.item()\n",
    "            training_loss += loss.item()\n",
    "\n",
    "            # Update\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_i % 100 == 99:\n",
    "                print('Batch: {}, Avg. Loss: {}'.format(batch_i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # Epoch results\n",
    "        training_loss /= len(train_loader)\n",
    "        print(f'[{round(time.time() - start, 3)} secs] Epoch: {epoch+1}/{epochs}', end='')\n",
    "        print(f', Training loss: {training_loss}', end='\\n\\n')\n",
    "        history.append(training_loss)\n",
    "    \n",
    "    print('training finished.')\n",
    "    \n",
    "    date = str(datetime.now()).split('.')[0]    \n",
    "    model_path = f'.\\\\models\\\\model_{re.sub(r\"[^0-9]\", \"\", date)}.pt'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': training_loss\n",
    "    }, model_path)\n",
    "    \n",
    "    print('model saved.')\n",
    "    \n",
    "    return history\n",
    "\n",
    "def load_model(path, dataset):\n",
    "    dim = dataset[0]['X'].shape[0]\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = Autoencoder(input_dim=dim)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    train_loss = checkpoint['loss']\n",
    "    \n",
    "    return model, optimizer, epoch, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eleven-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(path='.\\\\data\\\\training.h5', key='normal')\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-joining",
   "metadata": {},
   "source": [
    "## Training new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tribal-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = train_dataset[0]['X'].shape[0]\n",
    "\n",
    "model = Autoencoder(input_dim=dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepted-benchmark",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model training...\n",
      "training on cuda\n",
      "Batch: 100, Avg. Loss: 0.15866318181157113\n",
      "Batch: 200, Avg. Loss: 0.1587778677046299\n",
      "Batch: 300, Avg. Loss: 0.1588214559853077\n",
      "Batch: 400, Avg. Loss: 0.15748187452554702\n",
      "Batch: 500, Avg. Loss: 0.1570701564848423\n",
      "Batch: 600, Avg. Loss: 0.15782595291733742\n",
      "Batch: 700, Avg. Loss: 0.15832166522741317\n",
      "Batch: 800, Avg. Loss: 0.15788631066679953\n",
      "Batch: 900, Avg. Loss: 0.15846067562699317\n",
      "Batch: 1000, Avg. Loss: 0.15777762085199357\n",
      "Batch: 1100, Avg. Loss: 0.15831221207976343\n",
      "Batch: 1200, Avg. Loss: 0.15810422986745834\n",
      "Batch: 1300, Avg. Loss: 0.1590543806552887\n",
      "Batch: 1400, Avg. Loss: 0.15723520144820213\n",
      "Batch: 1500, Avg. Loss: 0.15841972038149835\n",
      "Batch: 1600, Avg. Loss: 0.1580926398932934\n",
      "Batch: 1700, Avg. Loss: 0.15700656071305275\n",
      "Batch: 1800, Avg. Loss: 0.15746187850832938\n",
      "Batch: 1900, Avg. Loss: 0.15811118230223656\n",
      "[29.509 secs] Epoch: 1/100, Training loss: 0.15803474600416367\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15779236942529679\n",
      "Batch: 200, Avg. Loss: 0.15820424556732177\n",
      "Batch: 300, Avg. Loss: 0.15877820834517478\n",
      "Batch: 400, Avg. Loss: 0.15929468601942062\n",
      "Batch: 500, Avg. Loss: 0.15794212192296983\n",
      "Batch: 600, Avg. Loss: 0.1586043606698513\n",
      "Batch: 700, Avg. Loss: 0.15882411122322082\n",
      "Batch: 800, Avg. Loss: 0.1576812706887722\n",
      "Batch: 900, Avg. Loss: 0.1588780701160431\n",
      "Batch: 1000, Avg. Loss: 0.15993308484554292\n",
      "Batch: 1100, Avg. Loss: 0.1599573114514351\n",
      "Batch: 1200, Avg. Loss: 0.1582514986395836\n",
      "Batch: 1300, Avg. Loss: 0.1587658117711544\n",
      "Batch: 1400, Avg. Loss: 0.15847296729683877\n",
      "Batch: 1500, Avg. Loss: 0.15798670098185538\n",
      "Batch: 1600, Avg. Loss: 0.1583539815247059\n",
      "Batch: 1700, Avg. Loss: 0.157975165694952\n",
      "Batch: 1800, Avg. Loss: 0.1587596583366394\n",
      "Batch: 1900, Avg. Loss: 0.15938666060566903\n",
      "[29.404 secs] Epoch: 2/100, Training loss: 0.15859936130449495\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15900167539715768\n",
      "Batch: 200, Avg. Loss: 0.15912623643875123\n",
      "Batch: 300, Avg. Loss: 0.15814334854483605\n",
      "Batch: 400, Avg. Loss: 0.15965521842241287\n",
      "Batch: 500, Avg. Loss: 0.15867605611681937\n",
      "Batch: 600, Avg. Loss: 0.15875689655542374\n",
      "Batch: 700, Avg. Loss: 0.15823669239878654\n",
      "Batch: 800, Avg. Loss: 0.15729153662919998\n",
      "Batch: 900, Avg. Loss: 0.15761911630630493\n",
      "Batch: 1000, Avg. Loss: 0.15779439821839333\n",
      "Batch: 1100, Avg. Loss: 0.1575293019413948\n",
      "Batch: 1200, Avg. Loss: 0.15711746111512184\n",
      "Batch: 1300, Avg. Loss: 0.15736572340130806\n",
      "Batch: 1400, Avg. Loss: 0.15845530346035958\n",
      "Batch: 1500, Avg. Loss: 0.15845523104071618\n",
      "Batch: 1600, Avg. Loss: 0.15842398926615714\n",
      "Batch: 1700, Avg. Loss: 0.1582428938150406\n",
      "Batch: 1800, Avg. Loss: 0.15888211831450463\n",
      "Batch: 1900, Avg. Loss: 0.15827784731984137\n",
      "[29.546 secs] Epoch: 3/100, Training loss: 0.15823131612861413\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15743051201105118\n",
      "Batch: 200, Avg. Loss: 0.15842618837952613\n",
      "Batch: 300, Avg. Loss: 0.15722112044692038\n",
      "Batch: 400, Avg. Loss: 0.15711183980107307\n",
      "Batch: 500, Avg. Loss: 0.1566934260725975\n",
      "Batch: 600, Avg. Loss: 0.1569829426705837\n",
      "Batch: 700, Avg. Loss: 0.15803235575556754\n",
      "Batch: 800, Avg. Loss: 0.15844834670424462\n",
      "Batch: 900, Avg. Loss: 0.15739898949861528\n",
      "Batch: 1000, Avg. Loss: 0.15732282310724258\n",
      "Batch: 1100, Avg. Loss: 0.1587386131286621\n",
      "Batch: 1200, Avg. Loss: 0.1590913550555706\n",
      "Batch: 1300, Avg. Loss: 0.15945215821266173\n",
      "Batch: 1400, Avg. Loss: 0.15834809198975563\n",
      "Batch: 1500, Avg. Loss: 0.1581212018430233\n",
      "Batch: 1600, Avg. Loss: 0.1584971109032631\n",
      "Batch: 1700, Avg. Loss: 0.1582278749346733\n",
      "Batch: 1800, Avg. Loss: 0.15840943589806555\n",
      "Batch: 1900, Avg. Loss: 0.1581994363665581\n",
      "[29.39 secs] Epoch: 4/100, Training loss: 0.15799020658587482\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1573570716381073\n",
      "Batch: 200, Avg. Loss: 0.15749283462762834\n",
      "Batch: 300, Avg. Loss: 0.1575641018152237\n",
      "Batch: 400, Avg. Loss: 0.1582853864133358\n",
      "Batch: 500, Avg. Loss: 0.15644345730543135\n",
      "Batch: 600, Avg. Loss: 0.15750950306653977\n",
      "Batch: 700, Avg. Loss: 0.15739215448498725\n",
      "Batch: 800, Avg. Loss: 0.15801235556602478\n",
      "Batch: 900, Avg. Loss: 0.1572505097091198\n",
      "Batch: 1000, Avg. Loss: 0.15666683703660966\n",
      "Batch: 1100, Avg. Loss: 0.1575542248785496\n",
      "Batch: 1200, Avg. Loss: 0.15804713293910028\n",
      "Batch: 1300, Avg. Loss: 0.15810148179531097\n",
      "Batch: 1400, Avg. Loss: 0.1574679584801197\n",
      "Batch: 1500, Avg. Loss: 0.15656430631875992\n",
      "Batch: 1600, Avg. Loss: 0.1570367293059826\n",
      "Batch: 1700, Avg. Loss: 0.1567811033129692\n",
      "Batch: 1800, Avg. Loss: 0.15674538925290107\n",
      "Batch: 1900, Avg. Loss: 0.15684518128633498\n",
      "[29.392 secs] Epoch: 5/100, Training loss: 0.1572895231470847\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1563786193728447\n",
      "Batch: 200, Avg. Loss: 0.15646014481782913\n",
      "Batch: 300, Avg. Loss: 0.15752130135893821\n",
      "Batch: 400, Avg. Loss: 0.1562260390818119\n",
      "Batch: 500, Avg. Loss: 0.15615081325173377\n",
      "Batch: 600, Avg. Loss: 0.1571463280916214\n",
      "Batch: 700, Avg. Loss: 0.15664375960826873\n",
      "Batch: 800, Avg. Loss: 0.1556195981800556\n",
      "Batch: 900, Avg. Loss: 0.15678185656666754\n",
      "Batch: 1000, Avg. Loss: 0.1569637168943882\n",
      "Batch: 1100, Avg. Loss: 0.15631855085492133\n",
      "Batch: 1200, Avg. Loss: 0.1561971715092659\n",
      "Batch: 1300, Avg. Loss: 0.15705738306045533\n",
      "Batch: 1400, Avg. Loss: 0.15552300199866295\n",
      "Batch: 1500, Avg. Loss: 0.1558741845190525\n",
      "Batch: 1600, Avg. Loss: 0.15572116553783416\n",
      "Batch: 1700, Avg. Loss: 0.15670685559511185\n",
      "Batch: 1800, Avg. Loss: 0.15588985815644263\n",
      "Batch: 1900, Avg. Loss: 0.15611962154507636\n",
      "[29.38 secs] Epoch: 6/100, Training loss: 0.15642536499422185\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15629372954368592\n",
      "Batch: 200, Avg. Loss: 0.15539607390761376\n",
      "Batch: 300, Avg. Loss: 0.1563138535618782\n",
      "Batch: 400, Avg. Loss: 0.15578113302588462\n",
      "Batch: 500, Avg. Loss: 0.15562350019812585\n",
      "Batch: 600, Avg. Loss: 0.1556253355741501\n",
      "Batch: 700, Avg. Loss: 0.15656120017170905\n",
      "Batch: 800, Avg. Loss: 0.15619926571846007\n",
      "Batch: 900, Avg. Loss: 0.15534570574760437\n",
      "Batch: 1000, Avg. Loss: 0.1559069487452507\n",
      "Batch: 1100, Avg. Loss: 0.15613668382167817\n",
      "Batch: 1200, Avg. Loss: 0.15628295600414277\n",
      "Batch: 1300, Avg. Loss: 0.1549860192835331\n",
      "Batch: 1400, Avg. Loss: 0.15585401639342308\n",
      "Batch: 1500, Avg. Loss: 0.15492163673043252\n",
      "Batch: 1600, Avg. Loss: 0.15555358678102493\n",
      "Batch: 1700, Avg. Loss: 0.1563967987895012\n",
      "Batch: 1800, Avg. Loss: 0.15739914879202843\n",
      "Batch: 1900, Avg. Loss: 0.15575379624962807\n",
      "[29.412 secs] Epoch: 7/100, Training loss: 0.15589195567668399\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15747254148125647\n",
      "Batch: 200, Avg. Loss: 0.15636981412768364\n",
      "Batch: 300, Avg. Loss: 0.15670737996697426\n",
      "Batch: 400, Avg. Loss: 0.15688633784651757\n",
      "Batch: 500, Avg. Loss: 0.1562326192855835\n",
      "Batch: 600, Avg. Loss: 0.15522125035524367\n",
      "Batch: 700, Avg. Loss: 0.15547122597694396\n",
      "Batch: 800, Avg. Loss: 0.15582464575767518\n",
      "Batch: 900, Avg. Loss: 0.1561108273267746\n",
      "Batch: 1000, Avg. Loss: 0.15555521115660667\n",
      "Batch: 1100, Avg. Loss: 0.1560756656527519\n",
      "Batch: 1200, Avg. Loss: 0.15641539737582208\n",
      "Batch: 1300, Avg. Loss: 0.15699843868613242\n",
      "Batch: 1400, Avg. Loss: 0.15784280493855476\n",
      "Batch: 1500, Avg. Loss: 0.1572662614285946\n",
      "Batch: 1600, Avg. Loss: 0.15754227772355078\n",
      "Batch: 1700, Avg. Loss: 0.15610715612769127\n",
      "Batch: 1800, Avg. Loss: 0.15690617993474007\n",
      "Batch: 1900, Avg. Loss: 0.15762406706809998\n",
      "[29.43 secs] Epoch: 8/100, Training loss: 0.1565507807470515\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1570775343477726\n",
      "Batch: 200, Avg. Loss: 0.1571834607422352\n",
      "Batch: 300, Avg. Loss: 0.1553906300663948\n",
      "Batch: 400, Avg. Loss: 0.1561706282198429\n",
      "Batch: 500, Avg. Loss: 0.15577057361602784\n",
      "Batch: 600, Avg. Loss: 0.15593199998140336\n",
      "Batch: 700, Avg. Loss: 0.15605669662356378\n",
      "Batch: 800, Avg. Loss: 0.15677058666944504\n",
      "Batch: 900, Avg. Loss: 0.15641069829463958\n",
      "Batch: 1000, Avg. Loss: 0.15584206491708755\n",
      "Batch: 1100, Avg. Loss: 0.15693741515278817\n",
      "Batch: 1200, Avg. Loss: 0.15500398188829423\n",
      "Batch: 1300, Avg. Loss: 0.15732344463467599\n",
      "Batch: 1400, Avg. Loss: 0.1564335072040558\n",
      "Batch: 1500, Avg. Loss: 0.15547611072659492\n",
      "Batch: 1600, Avg. Loss: 0.1555181084573269\n",
      "Batch: 1700, Avg. Loss: 0.15568065136671067\n",
      "Batch: 1800, Avg. Loss: 0.1557111094892025\n",
      "Batch: 1900, Avg. Loss: 0.15599695175886155\n",
      "[29.432 secs] Epoch: 9/100, Training loss: 0.15610802336810434\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15694454491138457\n",
      "Batch: 200, Avg. Loss: 0.15716190919280051\n",
      "Batch: 300, Avg. Loss: 0.15650831669569015\n",
      "Batch: 400, Avg. Loss: 0.15606431499123574\n",
      "Batch: 500, Avg. Loss: 0.1570214645564556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg. Loss: 0.15635678485035898\n",
      "Batch: 700, Avg. Loss: 0.15555530816316604\n",
      "Batch: 800, Avg. Loss: 0.15750452518463134\n",
      "Batch: 900, Avg. Loss: 0.15658304944634438\n",
      "Batch: 1000, Avg. Loss: 0.15621553167700766\n",
      "Batch: 1100, Avg. Loss: 0.15562134623527527\n",
      "Batch: 1200, Avg. Loss: 0.15511239528656007\n",
      "Batch: 1300, Avg. Loss: 0.15585446923971177\n",
      "Batch: 1400, Avg. Loss: 0.15666435718536376\n",
      "Batch: 1500, Avg. Loss: 0.15643068492412568\n",
      "Batch: 1600, Avg. Loss: 0.15753284946084023\n",
      "Batch: 1700, Avg. Loss: 0.15781215235590934\n",
      "Batch: 1800, Avg. Loss: 0.15555067256093025\n",
      "Batch: 1900, Avg. Loss: 0.1569082583487034\n",
      "[29.356 secs] Epoch: 10/100, Training loss: 0.1564566586300075\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15634382054209708\n",
      "Batch: 200, Avg. Loss: 0.15501427859067918\n",
      "Batch: 300, Avg. Loss: 0.1566769964993\n",
      "Batch: 400, Avg. Loss: 0.15608716025948524\n",
      "Batch: 500, Avg. Loss: 0.15717800661921502\n",
      "Batch: 600, Avg. Loss: 0.15742026314139365\n",
      "Batch: 700, Avg. Loss: 0.15692965060472489\n",
      "Batch: 800, Avg. Loss: 0.15685843542218209\n",
      "Batch: 900, Avg. Loss: 0.1570674131810665\n",
      "Batch: 1000, Avg. Loss: 0.1566631932556629\n",
      "Batch: 1100, Avg. Loss: 0.15659507021307945\n",
      "Batch: 1200, Avg. Loss: 0.15609948739409446\n",
      "Batch: 1300, Avg. Loss: 0.157190533131361\n",
      "Batch: 1400, Avg. Loss: 0.15731273710727692\n",
      "Batch: 1500, Avg. Loss: 0.15650319695472717\n",
      "Batch: 1600, Avg. Loss: 0.15737217515707017\n",
      "Batch: 1700, Avg. Loss: 0.1584588097035885\n",
      "Batch: 1800, Avg. Loss: 0.1574136011302471\n",
      "Batch: 1900, Avg. Loss: 0.15598828047513963\n",
      "[29.499 secs] Epoch: 11/100, Training loss: 0.15680921196693529\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1575492362678051\n",
      "Batch: 200, Avg. Loss: 0.1569198477268219\n",
      "Batch: 300, Avg. Loss: 0.15753425881266594\n",
      "Batch: 400, Avg. Loss: 0.15610226035118102\n",
      "Batch: 500, Avg. Loss: 0.15574099972844124\n",
      "Batch: 600, Avg. Loss: 0.1567356562614441\n",
      "Batch: 700, Avg. Loss: 0.1562869256734848\n",
      "Batch: 800, Avg. Loss: 0.15769519165158272\n",
      "Batch: 900, Avg. Loss: 0.1555900104343891\n",
      "Batch: 1000, Avg. Loss: 0.15626458287239076\n",
      "Batch: 1100, Avg. Loss: 0.15675733521580695\n",
      "Batch: 1200, Avg. Loss: 0.15677637323737145\n",
      "Batch: 1300, Avg. Loss: 0.1566540467739105\n",
      "Batch: 1400, Avg. Loss: 0.1553262361884117\n",
      "Batch: 1500, Avg. Loss: 0.15623571798205377\n",
      "Batch: 1600, Avg. Loss: 0.15572170838713645\n",
      "Batch: 1700, Avg. Loss: 0.15561727985739707\n",
      "Batch: 1800, Avg. Loss: 0.15679974466562271\n",
      "Batch: 1900, Avg. Loss: 0.15653793945908545\n",
      "[29.395 secs] Epoch: 12/100, Training loss: 0.1564799560693416\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15705113127827644\n",
      "Batch: 200, Avg. Loss: 0.15582070142030716\n",
      "Batch: 300, Avg. Loss: 0.15562017634510994\n",
      "Batch: 400, Avg. Loss: 0.1554509474337101\n",
      "Batch: 500, Avg. Loss: 0.15445467606186866\n",
      "Batch: 600, Avg. Loss: 0.15663479670882224\n",
      "Batch: 700, Avg. Loss: 0.15496223613619806\n",
      "Batch: 800, Avg. Loss: 0.15524169638752938\n",
      "Batch: 900, Avg. Loss: 0.15693028032779693\n",
      "Batch: 1000, Avg. Loss: 0.15436571702361107\n",
      "Batch: 1100, Avg. Loss: 0.15608372941613197\n",
      "Batch: 1200, Avg. Loss: 0.15586180180311204\n",
      "Batch: 1300, Avg. Loss: 0.15652985751628876\n",
      "Batch: 1400, Avg. Loss: 0.15561247736215592\n",
      "Batch: 1500, Avg. Loss: 0.15565757751464843\n",
      "Batch: 1600, Avg. Loss: 0.15704349011182786\n",
      "Batch: 1700, Avg. Loss: 0.1555286380648613\n",
      "Batch: 1800, Avg. Loss: 0.15547460421919823\n",
      "Batch: 1900, Avg. Loss: 0.15696193978190423\n",
      "[29.391 secs] Epoch: 13/100, Training loss: 0.15585025434240227\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15649116173386574\n",
      "Batch: 200, Avg. Loss: 0.1561271744966507\n",
      "Batch: 300, Avg. Loss: 0.15435961201786996\n",
      "Batch: 400, Avg. Loss: 0.15530215755105017\n",
      "Batch: 500, Avg. Loss: 0.1544303134083748\n",
      "Batch: 600, Avg. Loss: 0.15592800259590148\n",
      "Batch: 700, Avg. Loss: 0.15456644624471663\n",
      "Batch: 800, Avg. Loss: 0.1559435324370861\n",
      "Batch: 900, Avg. Loss: 0.15635806426405907\n",
      "Batch: 1000, Avg. Loss: 0.1546735167503357\n",
      "Batch: 1100, Avg. Loss: 0.15484879061579704\n",
      "Batch: 1200, Avg. Loss: 0.1556300190091133\n",
      "Batch: 1300, Avg. Loss: 0.15551201209425927\n",
      "Batch: 1400, Avg. Loss: 0.15566461324691772\n",
      "Batch: 1500, Avg. Loss: 0.15607476681470872\n",
      "Batch: 1600, Avg. Loss: 0.1553395138680935\n",
      "Batch: 1700, Avg. Loss: 0.1554584403336048\n",
      "Batch: 1800, Avg. Loss: 0.1557295122742653\n",
      "Batch: 1900, Avg. Loss: 0.15399341210722922\n",
      "[29.537 secs] Epoch: 14/100, Training loss: 0.15539603420326384\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15433889538049697\n",
      "Batch: 200, Avg. Loss: 0.15462767094373703\n",
      "Batch: 300, Avg. Loss: 0.15453713670372962\n",
      "Batch: 400, Avg. Loss: 0.1562406538426876\n",
      "Batch: 500, Avg. Loss: 0.1558258453011513\n",
      "Batch: 600, Avg. Loss: 0.1554525226354599\n",
      "Batch: 700, Avg. Loss: 0.15515224069356917\n",
      "Batch: 800, Avg. Loss: 0.1545170147716999\n",
      "Batch: 900, Avg. Loss: 0.15521115228533744\n",
      "Batch: 1000, Avg. Loss: 0.1547550268471241\n",
      "Batch: 1100, Avg. Loss: 0.15357332542538643\n",
      "Batch: 1200, Avg. Loss: 0.1548157550394535\n",
      "Batch: 1300, Avg. Loss: 0.1541736650466919\n",
      "Batch: 1400, Avg. Loss: 0.15464426338672638\n",
      "Batch: 1500, Avg. Loss: 0.15515748873353005\n",
      "Batch: 1600, Avg. Loss: 0.15501413583755494\n",
      "Batch: 1700, Avg. Loss: 0.15432649835944176\n",
      "Batch: 1800, Avg. Loss: 0.15510399773716926\n",
      "Batch: 1900, Avg. Loss: 0.15548283651471137\n",
      "[29.633 secs] Epoch: 15/100, Training loss: 0.15489498863688755\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1551964697241783\n",
      "Batch: 200, Avg. Loss: 0.15484814286231996\n",
      "Batch: 300, Avg. Loss: 0.15589187443256378\n",
      "Batch: 400, Avg. Loss: 0.15560969218611717\n",
      "Batch: 500, Avg. Loss: 0.15623245656490325\n",
      "Batch: 600, Avg. Loss: 0.1555440254509449\n",
      "Batch: 700, Avg. Loss: 0.1545161111652851\n",
      "Batch: 800, Avg. Loss: 0.15416595011949538\n",
      "Batch: 900, Avg. Loss: 0.1552860352396965\n",
      "Batch: 1000, Avg. Loss: 0.1539752447605133\n",
      "Batch: 1100, Avg. Loss: 0.15568694844841957\n",
      "Batch: 1200, Avg. Loss: 0.15460769549012185\n",
      "Batch: 1300, Avg. Loss: 0.15352273732423782\n",
      "Batch: 1400, Avg. Loss: 0.15367520332336426\n",
      "Batch: 1500, Avg. Loss: 0.15421657890081406\n",
      "Batch: 1600, Avg. Loss: 0.1543627816438675\n",
      "Batch: 1700, Avg. Loss: 0.15321414828300475\n",
      "Batch: 1800, Avg. Loss: 0.15410953253507614\n",
      "Batch: 1900, Avg. Loss: 0.15406492918729783\n",
      "[29.403 secs] Epoch: 16/100, Training loss: 0.15471022775131701\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15434129908680916\n",
      "Batch: 200, Avg. Loss: 0.15427548348903655\n",
      "Batch: 300, Avg. Loss: 0.15439189329743386\n",
      "Batch: 400, Avg. Loss: 0.15353937700390816\n",
      "Batch: 500, Avg. Loss: 0.1535927939414978\n",
      "Batch: 600, Avg. Loss: 0.15418190509080887\n",
      "Batch: 700, Avg. Loss: 0.1531753359735012\n",
      "Batch: 800, Avg. Loss: 0.15328180506825448\n",
      "Batch: 900, Avg. Loss: 0.15503576457500456\n",
      "Batch: 1000, Avg. Loss: 0.15542955994606017\n",
      "Batch: 1100, Avg. Loss: 0.15409276604652405\n",
      "Batch: 1200, Avg. Loss: 0.156766387373209\n",
      "Batch: 1300, Avg. Loss: 0.15529875665903092\n",
      "Batch: 1400, Avg. Loss: 0.15452926054596902\n",
      "Batch: 1500, Avg. Loss: 0.15511221021413804\n",
      "Batch: 1600, Avg. Loss: 0.15530491054058074\n",
      "Batch: 1700, Avg. Loss: 0.15419037908315658\n",
      "Batch: 1800, Avg. Loss: 0.15383947044610977\n",
      "Batch: 1900, Avg. Loss: 0.15333353236317634\n",
      "[29.374 secs] Epoch: 17/100, Training loss: 0.1543834897839181\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1557652959227562\n",
      "Batch: 200, Avg. Loss: 0.15415403500199318\n",
      "Batch: 300, Avg. Loss: 0.1540617088973522\n",
      "Batch: 400, Avg. Loss: 0.15419307231903076\n",
      "Batch: 500, Avg. Loss: 0.15382401376962662\n",
      "Batch: 600, Avg. Loss: 0.15622270628809928\n",
      "Batch: 700, Avg. Loss: 0.15597246170043946\n",
      "Batch: 800, Avg. Loss: 0.1539590512216091\n",
      "Batch: 900, Avg. Loss: 0.15427905991673468\n",
      "Batch: 1000, Avg. Loss: 0.15418421655893325\n",
      "Batch: 1100, Avg. Loss: 0.15365760535001755\n",
      "Batch: 1200, Avg. Loss: 0.15475707456469537\n",
      "Batch: 1300, Avg. Loss: 0.15490034803748132\n",
      "Batch: 1400, Avg. Loss: 0.1541574417054653\n",
      "Batch: 1500, Avg. Loss: 0.1545968870818615\n",
      "Batch: 1600, Avg. Loss: 0.15487999200820923\n",
      "Batch: 1700, Avg. Loss: 0.1542161963880062\n",
      "Batch: 1800, Avg. Loss: 0.1543923944234848\n",
      "Batch: 1900, Avg. Loss: 0.1521824336051941\n",
      "[29.436 secs] Epoch: 18/100, Training loss: 0.1544357205578102\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1534047418832779\n",
      "Batch: 200, Avg. Loss: 0.15372475609183311\n",
      "Batch: 300, Avg. Loss: 0.15482844576239585\n",
      "Batch: 400, Avg. Loss: 0.15485019028186797\n",
      "Batch: 500, Avg. Loss: 0.15406706243753432\n",
      "Batch: 600, Avg. Loss: 0.1539733326435089\n",
      "Batch: 700, Avg. Loss: 0.15382633358240128\n",
      "Batch: 800, Avg. Loss: 0.15512251272797584\n",
      "Batch: 900, Avg. Loss: 0.15379322066903114\n",
      "Batch: 1000, Avg. Loss: 0.15461015030741693\n",
      "Batch: 1100, Avg. Loss: 0.1545218189060688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1200, Avg. Loss: 0.15456588089466095\n",
      "Batch: 1300, Avg. Loss: 0.1543232600390911\n",
      "Batch: 1400, Avg. Loss: 0.1541843019425869\n",
      "Batch: 1500, Avg. Loss: 0.1546381551027298\n",
      "Batch: 1600, Avg. Loss: 0.15382508605718612\n",
      "Batch: 1700, Avg. Loss: 0.15428530991077424\n",
      "Batch: 1800, Avg. Loss: 0.15385766983032226\n",
      "Batch: 1900, Avg. Loss: 0.1550352095067501\n",
      "[29.411 secs] Epoch: 19/100, Training loss: 0.15425047044286708\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15422604322433472\n",
      "Batch: 200, Avg. Loss: 0.15364638239145278\n",
      "Batch: 300, Avg. Loss: 0.1546758659183979\n",
      "Batch: 400, Avg. Loss: 0.1533428616821766\n",
      "Batch: 500, Avg. Loss: 0.15405820548534394\n",
      "Batch: 600, Avg. Loss: 0.15466688752174376\n",
      "Batch: 700, Avg. Loss: 0.1548996214568615\n",
      "Batch: 800, Avg. Loss: 0.15554433301091194\n",
      "Batch: 900, Avg. Loss: 0.15481685489416122\n",
      "Batch: 1000, Avg. Loss: 0.1538917465507984\n",
      "Batch: 1100, Avg. Loss: 0.1540569543838501\n",
      "Batch: 1200, Avg. Loss: 0.1526583594083786\n",
      "Batch: 1300, Avg. Loss: 0.15440940394997596\n",
      "Batch: 1400, Avg. Loss: 0.1555667246878147\n",
      "Batch: 1500, Avg. Loss: 0.15388660192489623\n",
      "Batch: 1600, Avg. Loss: 0.15429341956973075\n",
      "Batch: 1700, Avg. Loss: 0.15521276235580445\n",
      "Batch: 1800, Avg. Loss: 0.15479204595088958\n",
      "Batch: 1900, Avg. Loss: 0.15489654421806334\n",
      "[29.364 secs] Epoch: 20/100, Training loss: 0.15441620885990293\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1543533346056938\n",
      "Batch: 200, Avg. Loss: 0.1545085906982422\n",
      "Batch: 300, Avg. Loss: 0.1540290528535843\n",
      "Batch: 400, Avg. Loss: 0.15337254583835602\n",
      "Batch: 500, Avg. Loss: 0.15323480889201163\n",
      "Batch: 600, Avg. Loss: 0.15498830124735832\n",
      "Batch: 700, Avg. Loss: 0.15519628554582596\n",
      "Batch: 800, Avg. Loss: 0.15449900582432746\n",
      "Batch: 900, Avg. Loss: 0.1532420913875103\n",
      "Batch: 1000, Avg. Loss: 0.15382844910025598\n",
      "Batch: 1100, Avg. Loss: 0.15346524447202683\n",
      "Batch: 1200, Avg. Loss: 0.15333994328975678\n",
      "Batch: 1300, Avg. Loss: 0.15347408413887023\n",
      "Batch: 1400, Avg. Loss: 0.15384856447577477\n",
      "Batch: 1500, Avg. Loss: 0.15506115779280663\n",
      "Batch: 1600, Avg. Loss: 0.15313899010419846\n",
      "Batch: 1700, Avg. Loss: 0.15346763014793396\n",
      "Batch: 1800, Avg. Loss: 0.1554074043035507\n",
      "Batch: 1900, Avg. Loss: 0.15373089984059335\n",
      "[29.384 secs] Epoch: 21/100, Training loss: 0.15397470967582938\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15510651022195815\n",
      "Batch: 200, Avg. Loss: 0.15468589693307877\n",
      "Batch: 300, Avg. Loss: 0.15433761432766915\n",
      "Batch: 400, Avg. Loss: 0.15369976669549942\n",
      "Batch: 500, Avg. Loss: 0.1528936007618904\n",
      "Batch: 600, Avg. Loss: 0.15446142747998237\n",
      "Batch: 700, Avg. Loss: 0.1536906211078167\n",
      "Batch: 800, Avg. Loss: 0.1532587729394436\n",
      "Batch: 900, Avg. Loss: 0.15347104176878928\n",
      "Batch: 1000, Avg. Loss: 0.15310708850622176\n",
      "Batch: 1100, Avg. Loss: 0.15433282300829887\n",
      "Batch: 1200, Avg. Loss: 0.15384148865938185\n",
      "Batch: 1300, Avg. Loss: 0.15433461338281632\n",
      "Batch: 1400, Avg. Loss: 0.15430865556001663\n",
      "Batch: 1500, Avg. Loss: 0.15305093720555304\n",
      "Batch: 1600, Avg. Loss: 0.15519450217485428\n",
      "Batch: 1700, Avg. Loss: 0.15318422198295592\n",
      "Batch: 1800, Avg. Loss: 0.1529547555744648\n",
      "Batch: 1900, Avg. Loss: 0.1539183647930622\n",
      "[29.52 secs] Epoch: 22/100, Training loss: 0.15388561636514528\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15275084033608435\n",
      "Batch: 200, Avg. Loss: 0.1526579186320305\n",
      "Batch: 300, Avg. Loss: 0.1532968360185623\n",
      "Batch: 400, Avg. Loss: 0.15426627650856972\n",
      "Batch: 500, Avg. Loss: 0.15405423566699028\n",
      "Batch: 600, Avg. Loss: 0.15282479107379912\n",
      "Batch: 700, Avg. Loss: 0.15309176325798035\n",
      "Batch: 800, Avg. Loss: 0.15415557906031607\n",
      "Batch: 900, Avg. Loss: 0.15317185774445533\n",
      "Batch: 1000, Avg. Loss: 0.15396275833249093\n",
      "Batch: 1100, Avg. Loss: 0.15394197300076484\n",
      "Batch: 1200, Avg. Loss: 0.1547890068590641\n",
      "Batch: 1300, Avg. Loss: 0.15323180377483367\n",
      "Batch: 1400, Avg. Loss: 0.15349900901317595\n",
      "Batch: 1500, Avg. Loss: 0.15342691898345948\n",
      "Batch: 1600, Avg. Loss: 0.15314622715115547\n",
      "Batch: 1700, Avg. Loss: 0.15314335882663727\n",
      "Batch: 1800, Avg. Loss: 0.15290561735630034\n",
      "Batch: 1900, Avg. Loss: 0.15303875058889388\n",
      "[29.465 secs] Epoch: 23/100, Training loss: 0.15344715322021818\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15354437246918679\n",
      "Batch: 200, Avg. Loss: 0.15353064686059953\n",
      "Batch: 300, Avg. Loss: 0.15393158540129662\n",
      "Batch: 400, Avg. Loss: 0.153379607796669\n",
      "Batch: 500, Avg. Loss: 0.15292300283908844\n",
      "Batch: 600, Avg. Loss: 0.1530398455262184\n",
      "Batch: 700, Avg. Loss: 0.15305644139647484\n",
      "Batch: 800, Avg. Loss: 0.15291297137737275\n",
      "Batch: 900, Avg. Loss: 0.15249185040593147\n",
      "Batch: 1000, Avg. Loss: 0.15403942584991456\n",
      "Batch: 1100, Avg. Loss: 0.15352479487657547\n",
      "Batch: 1200, Avg. Loss: 0.15261405631899833\n",
      "Batch: 1300, Avg. Loss: 0.15426054626703262\n",
      "Batch: 1400, Avg. Loss: 0.15299002945423126\n",
      "Batch: 1500, Avg. Loss: 0.1536509272456169\n",
      "Batch: 1600, Avg. Loss: 0.15331633657217025\n",
      "Batch: 1700, Avg. Loss: 0.15328835666179658\n",
      "Batch: 1800, Avg. Loss: 0.15541504845023155\n",
      "Batch: 1900, Avg. Loss: 0.15427737742662428\n",
      "[29.33 secs] Epoch: 24/100, Training loss: 0.15348443407241252\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15383397474884986\n",
      "Batch: 200, Avg. Loss: 0.15353312954306603\n",
      "Batch: 300, Avg. Loss: 0.15353472620248795\n",
      "Batch: 400, Avg. Loss: 0.1530250546336174\n",
      "Batch: 500, Avg. Loss: 0.15515959948301317\n",
      "Batch: 600, Avg. Loss: 0.15401932507753371\n",
      "Batch: 700, Avg. Loss: 0.15316458627581597\n",
      "Batch: 800, Avg. Loss: 0.15309320524334907\n",
      "Batch: 900, Avg. Loss: 0.15314779832959174\n",
      "Batch: 1000, Avg. Loss: 0.15394268736243247\n",
      "Batch: 1100, Avg. Loss: 0.1541600050032139\n",
      "Batch: 1200, Avg. Loss: 0.15388918071985244\n",
      "Batch: 1300, Avg. Loss: 0.15323117300868033\n",
      "Batch: 1400, Avg. Loss: 0.15473343893885613\n",
      "Batch: 1500, Avg. Loss: 0.15345138788223267\n",
      "Batch: 1600, Avg. Loss: 0.1537964029610157\n",
      "Batch: 1700, Avg. Loss: 0.15284478589892386\n",
      "Batch: 1800, Avg. Loss: 0.15373662680387498\n",
      "Batch: 1900, Avg. Loss: 0.15314500749111176\n",
      "[29.325 secs] Epoch: 25/100, Training loss: 0.15364062494027333\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15345027521252633\n",
      "Batch: 200, Avg. Loss: 0.15348478510975838\n",
      "Batch: 300, Avg. Loss: 0.1533741457760334\n",
      "Batch: 400, Avg. Loss: 0.15352843597531318\n",
      "Batch: 500, Avg. Loss: 0.15342318072915076\n",
      "Batch: 600, Avg. Loss: 0.15441270545125008\n",
      "Batch: 700, Avg. Loss: 0.1544445525109768\n",
      "Batch: 800, Avg. Loss: 0.15318460747599602\n",
      "Batch: 900, Avg. Loss: 0.15327573254704474\n",
      "Batch: 1000, Avg. Loss: 0.15361542448401452\n",
      "Batch: 1100, Avg. Loss: 0.15374323964118958\n",
      "Batch: 1200, Avg. Loss: 0.15449914380908011\n",
      "Batch: 1300, Avg. Loss: 0.1536851355433464\n",
      "Batch: 1400, Avg. Loss: 0.15341254726052284\n",
      "Batch: 1500, Avg. Loss: 0.15357655093073844\n",
      "Batch: 1600, Avg. Loss: 0.15388469994068146\n",
      "Batch: 1700, Avg. Loss: 0.15555728495121002\n",
      "Batch: 1800, Avg. Loss: 0.15435405924916268\n",
      "Batch: 1900, Avg. Loss: 0.15420234441757202\n",
      "[29.408 secs] Epoch: 26/100, Training loss: 0.153859162342829\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15473243355751037\n",
      "Batch: 200, Avg. Loss: 0.15397251948714255\n",
      "Batch: 300, Avg. Loss: 0.15276174932718278\n",
      "Batch: 400, Avg. Loss: 0.15206512838602065\n",
      "Batch: 500, Avg. Loss: 0.1537892007827759\n",
      "Batch: 600, Avg. Loss: 0.15322909951210023\n",
      "Batch: 700, Avg. Loss: 0.1532956737279892\n",
      "Batch: 800, Avg. Loss: 0.15440516903996468\n",
      "Batch: 900, Avg. Loss: 0.15332499235868455\n",
      "Batch: 1000, Avg. Loss: 0.1529201516509056\n",
      "Batch: 1100, Avg. Loss: 0.15255964741110803\n",
      "Batch: 1200, Avg. Loss: 0.154386727809906\n",
      "Batch: 1300, Avg. Loss: 0.15342637553811073\n",
      "Batch: 1400, Avg. Loss: 0.1535698379576206\n",
      "Batch: 1500, Avg. Loss: 0.15337607458233835\n",
      "Batch: 1600, Avg. Loss: 0.15371270820498467\n",
      "Batch: 1700, Avg. Loss: 0.15364963799715042\n",
      "Batch: 1800, Avg. Loss: 0.15354771718382834\n",
      "Batch: 1900, Avg. Loss: 0.1529991465806961\n",
      "[29.391 secs] Epoch: 27/100, Training loss: 0.15350701981734108\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1538817447423935\n",
      "Batch: 200, Avg. Loss: 0.15252119436860084\n",
      "Batch: 300, Avg. Loss: 0.15373123526573182\n",
      "Batch: 400, Avg. Loss: 0.15310877576470375\n",
      "Batch: 500, Avg. Loss: 0.15376822233200074\n",
      "Batch: 600, Avg. Loss: 0.15314458712935447\n",
      "Batch: 700, Avg. Loss: 0.1532374256849289\n",
      "Batch: 800, Avg. Loss: 0.15162443339824677\n",
      "Batch: 900, Avg. Loss: 0.1530139510333538\n",
      "Batch: 1000, Avg. Loss: 0.15413142755627632\n",
      "Batch: 1100, Avg. Loss: 0.15387962907552719\n",
      "Batch: 1200, Avg. Loss: 0.15390992045402527\n",
      "Batch: 1300, Avg. Loss: 0.15327377542853354\n",
      "Batch: 1400, Avg. Loss: 0.1540970639884472\n",
      "Batch: 1500, Avg. Loss: 0.15406564816832544\n",
      "Batch: 1600, Avg. Loss: 0.15393587991595267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1700, Avg. Loss: 0.15400921627879144\n",
      "Batch: 1800, Avg. Loss: 0.15341089516878129\n",
      "Batch: 1900, Avg. Loss: 0.15388143166899682\n",
      "[29.4 secs] Epoch: 28/100, Training loss: 0.15352314584788426\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15392174944281578\n",
      "Batch: 200, Avg. Loss: 0.15326053857803346\n",
      "Batch: 300, Avg. Loss: 0.15325309321284294\n",
      "Batch: 400, Avg. Loss: 0.153187772333622\n",
      "Batch: 500, Avg. Loss: 0.15311864241957665\n",
      "Batch: 600, Avg. Loss: 0.15366484820842743\n",
      "Batch: 700, Avg. Loss: 0.15337931737303734\n",
      "Batch: 800, Avg. Loss: 0.15390020594000817\n",
      "Batch: 900, Avg. Loss: 0.15494948863983155\n",
      "Batch: 1000, Avg. Loss: 0.15413354098796844\n",
      "Batch: 1100, Avg. Loss: 0.15388424560427666\n",
      "Batch: 1200, Avg. Loss: 0.15348630473017694\n",
      "Batch: 1300, Avg. Loss: 0.15347436740994452\n",
      "Batch: 1400, Avg. Loss: 0.15434264823794364\n",
      "Batch: 1500, Avg. Loss: 0.15313375532627105\n",
      "Batch: 1600, Avg. Loss: 0.1526926089823246\n",
      "Batch: 1700, Avg. Loss: 0.15358122140169145\n",
      "Batch: 1800, Avg. Loss: 0.15541292279958724\n",
      "Batch: 1900, Avg. Loss: 0.1552990436553955\n",
      "[29.398 secs] Epoch: 29/100, Training loss: 0.15382142229998977\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15499013230204584\n",
      "Batch: 200, Avg. Loss: 0.15423959076404573\n",
      "Batch: 300, Avg. Loss: 0.15414427027106284\n",
      "Batch: 400, Avg. Loss: 0.1542551463842392\n",
      "Batch: 500, Avg. Loss: 0.15492615312337876\n",
      "Batch: 600, Avg. Loss: 0.1526983253657818\n",
      "Batch: 700, Avg. Loss: 0.15512756109237671\n",
      "Batch: 800, Avg. Loss: 0.15495671927928925\n",
      "Batch: 900, Avg. Loss: 0.1550236850976944\n",
      "Batch: 1000, Avg. Loss: 0.15419351160526276\n",
      "Batch: 1100, Avg. Loss: 0.15567748203873635\n",
      "Batch: 1200, Avg. Loss: 0.15542178228497505\n",
      "Batch: 1300, Avg. Loss: 0.15475767612457275\n",
      "Batch: 1400, Avg. Loss: 0.15462041780352592\n",
      "Batch: 1500, Avg. Loss: 0.15491012513637542\n",
      "Batch: 1600, Avg. Loss: 0.15461736619472505\n",
      "Batch: 1700, Avg. Loss: 0.15434308141469955\n",
      "Batch: 1800, Avg. Loss: 0.1552915830910206\n",
      "Batch: 1900, Avg. Loss: 0.15429876014590263\n",
      "[29.342 secs] Epoch: 30/100, Training loss: 0.15466241475991607\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15502352848649026\n",
      "Batch: 200, Avg. Loss: 0.15464857205748558\n",
      "Batch: 300, Avg. Loss: 0.15569402009248734\n",
      "Batch: 400, Avg. Loss: 0.15448513880372047\n",
      "Batch: 500, Avg. Loss: 0.1549268187582493\n",
      "Batch: 600, Avg. Loss: 0.15539997845888137\n",
      "Batch: 700, Avg. Loss: 0.1550964730978012\n",
      "Batch: 800, Avg. Loss: 0.1552374057471752\n",
      "Batch: 900, Avg. Loss: 0.15568328142166138\n",
      "Batch: 1000, Avg. Loss: 0.15363153889775277\n",
      "Batch: 1100, Avg. Loss: 0.15558241158723832\n",
      "Batch: 1200, Avg. Loss: 0.15522146359086036\n",
      "Batch: 1300, Avg. Loss: 0.15483366146683694\n",
      "Batch: 1400, Avg. Loss: 0.15419865921139717\n",
      "Batch: 1500, Avg. Loss: 0.1555628450214863\n",
      "Batch: 1600, Avg. Loss: 0.15486850947141648\n",
      "Batch: 1700, Avg. Loss: 0.15494272187352182\n",
      "Batch: 1800, Avg. Loss: 0.15566391974687577\n",
      "Batch: 1900, Avg. Loss: 0.1556555861234665\n",
      "[29.365 secs] Epoch: 31/100, Training loss: 0.15509815765744955\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1548352885246277\n",
      "Batch: 200, Avg. Loss: 0.15545835018157958\n",
      "Batch: 300, Avg. Loss: 0.1556321831047535\n",
      "Batch: 400, Avg. Loss: 0.15485741078853607\n",
      "Batch: 500, Avg. Loss: 0.15520605370402335\n",
      "Batch: 600, Avg. Loss: 0.1545035019516945\n",
      "Batch: 700, Avg. Loss: 0.15517256930470466\n",
      "Batch: 800, Avg. Loss: 0.15585978090763092\n",
      "Batch: 900, Avg. Loss: 0.15602431908249856\n",
      "Batch: 1000, Avg. Loss: 0.1546161788702011\n",
      "Batch: 1100, Avg. Loss: 0.15501896917819977\n",
      "Batch: 1200, Avg. Loss: 0.15486053958535195\n",
      "Batch: 1300, Avg. Loss: 0.154340980052948\n",
      "Batch: 1400, Avg. Loss: 0.1553153458237648\n",
      "Batch: 1500, Avg. Loss: 0.15675033241510392\n",
      "Batch: 1600, Avg. Loss: 0.15591374680399894\n",
      "Batch: 1700, Avg. Loss: 0.15505600243806839\n",
      "Batch: 1800, Avg. Loss: 0.15592946112155914\n",
      "Batch: 1900, Avg. Loss: 0.15474417075514793\n",
      "[29.303 secs] Epoch: 32/100, Training loss: 0.15524998284350153\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15479012772440912\n",
      "Batch: 200, Avg. Loss: 0.1538604113459587\n",
      "Batch: 300, Avg. Loss: 0.15545950174331666\n",
      "Batch: 400, Avg. Loss: 0.15517946049571038\n",
      "Batch: 500, Avg. Loss: 0.15431464374065398\n",
      "Batch: 600, Avg. Loss: 0.1549903294444084\n",
      "Batch: 700, Avg. Loss: 0.15603436693549155\n",
      "Batch: 800, Avg. Loss: 0.15484216421842575\n",
      "Batch: 900, Avg. Loss: 0.15505740210413932\n",
      "Batch: 1000, Avg. Loss: 0.15402404353022575\n",
      "Batch: 1100, Avg. Loss: 0.15459493577480315\n",
      "Batch: 1200, Avg. Loss: 0.15549551993608474\n",
      "Batch: 1300, Avg. Loss: 0.15491741627454758\n",
      "Batch: 1400, Avg. Loss: 0.15416890770196914\n",
      "Batch: 1500, Avg. Loss: 0.15557269811630248\n",
      "Batch: 1600, Avg. Loss: 0.1544762647151947\n",
      "Batch: 1700, Avg. Loss: 0.15513216093182564\n",
      "Batch: 1800, Avg. Loss: 0.1547500902414322\n",
      "Batch: 1900, Avg. Loss: 0.15415395691990852\n",
      "[29.738 secs] Epoch: 33/100, Training loss: 0.15483010779139694\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15505218759179115\n",
      "Batch: 200, Avg. Loss: 0.1558138243854046\n",
      "Batch: 300, Avg. Loss: 0.15524966895580292\n",
      "Batch: 400, Avg. Loss: 0.1541113770008087\n",
      "Batch: 500, Avg. Loss: 0.15516198083758354\n",
      "Batch: 600, Avg. Loss: 0.15523253604769707\n",
      "Batch: 700, Avg. Loss: 0.15497227221727372\n",
      "Batch: 800, Avg. Loss: 0.15616824105381966\n",
      "Batch: 900, Avg. Loss: 0.15534352883696556\n",
      "Batch: 1000, Avg. Loss: 0.15672261789441108\n",
      "Batch: 1100, Avg. Loss: 0.1549841594696045\n",
      "Batch: 1200, Avg. Loss: 0.15484983444213868\n",
      "Batch: 1300, Avg. Loss: 0.15556279629468917\n",
      "Batch: 1400, Avg. Loss: 0.15509978652000428\n",
      "Batch: 1500, Avg. Loss: 0.1548421387374401\n",
      "Batch: 1600, Avg. Loss: 0.1556338645517826\n",
      "Batch: 1700, Avg. Loss: 0.1555850537121296\n",
      "Batch: 1800, Avg. Loss: 0.15354189723730088\n",
      "Batch: 1900, Avg. Loss: 0.1558873997628689\n",
      "[29.445 secs] Epoch: 34/100, Training loss: 0.15525739805481206\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15556043595075608\n",
      "Batch: 200, Avg. Loss: 0.155640100389719\n",
      "Batch: 300, Avg. Loss: 0.1547995725274086\n",
      "Batch: 400, Avg. Loss: 0.15520893335342406\n",
      "Batch: 500, Avg. Loss: 0.15573378875851632\n",
      "Batch: 600, Avg. Loss: 0.1537742108106613\n",
      "Batch: 700, Avg. Loss: 0.15515697583556176\n",
      "Batch: 800, Avg. Loss: 0.15597192361950873\n",
      "Batch: 900, Avg. Loss: 0.15553574725985528\n",
      "Batch: 1000, Avg. Loss: 0.15420396581292153\n",
      "Batch: 1100, Avg. Loss: 0.15421391621232033\n",
      "Batch: 1200, Avg. Loss: 0.15521447867155075\n",
      "Batch: 1300, Avg. Loss: 0.15372890025377273\n",
      "Batch: 1400, Avg. Loss: 0.15491705402731895\n",
      "Batch: 1500, Avg. Loss: 0.15635541394352914\n",
      "Batch: 1600, Avg. Loss: 0.1555171762406826\n",
      "Batch: 1700, Avg. Loss: 0.15436837330460548\n",
      "Batch: 1800, Avg. Loss: 0.1542602127790451\n",
      "Batch: 1900, Avg. Loss: 0.15330567538738252\n",
      "[29.381 secs] Epoch: 35/100, Training loss: 0.15487921246334133\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15399760380387306\n",
      "Batch: 200, Avg. Loss: 0.15442959740757942\n",
      "Batch: 300, Avg. Loss: 0.15466397225856782\n",
      "Batch: 400, Avg. Loss: 0.15420502215623855\n",
      "Batch: 500, Avg. Loss: 0.15346990764141083\n",
      "Batch: 600, Avg. Loss: 0.1535524246096611\n",
      "Batch: 700, Avg. Loss: 0.15351527556777\n",
      "Batch: 800, Avg. Loss: 0.15428324431180954\n",
      "Batch: 900, Avg. Loss: 0.15393238097429277\n",
      "Batch: 1000, Avg. Loss: 0.1539550842344761\n",
      "Batch: 1100, Avg. Loss: 0.152619566321373\n",
      "Batch: 1200, Avg. Loss: 0.15318450778722764\n",
      "Batch: 1300, Avg. Loss: 0.15394106179475783\n",
      "Batch: 1400, Avg. Loss: 0.15445780947804452\n",
      "Batch: 1500, Avg. Loss: 0.15350840792059897\n",
      "Batch: 1600, Avg. Loss: 0.15362217396497727\n",
      "Batch: 1700, Avg. Loss: 0.15366857007145882\n",
      "Batch: 1800, Avg. Loss: 0.15334651201963426\n",
      "Batch: 1900, Avg. Loss: 0.15324006035923957\n",
      "[29.392 secs] Epoch: 36/100, Training loss: 0.153775638367832\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15404904052615165\n",
      "Batch: 200, Avg. Loss: 0.15322453454136847\n",
      "Batch: 300, Avg. Loss: 0.15351585268974305\n",
      "Batch: 400, Avg. Loss: 0.1527137929201126\n",
      "Batch: 500, Avg. Loss: 0.15300801783800125\n",
      "Batch: 600, Avg. Loss: 0.1550098790228367\n",
      "Batch: 700, Avg. Loss: 0.1545140664279461\n",
      "Batch: 800, Avg. Loss: 0.1539155934751034\n",
      "Batch: 900, Avg. Loss: 0.15275405943393708\n",
      "Batch: 1000, Avg. Loss: 0.15261668145656584\n",
      "Batch: 1100, Avg. Loss: 0.1548156225681305\n",
      "Batch: 1200, Avg. Loss: 0.15358020424842833\n",
      "Batch: 1300, Avg. Loss: 0.15347887426614762\n",
      "Batch: 1400, Avg. Loss: 0.15469790503382683\n",
      "Batch: 1500, Avg. Loss: 0.15405104130506517\n",
      "Batch: 1600, Avg. Loss: 0.15458900168538092\n",
      "Batch: 1700, Avg. Loss: 0.15327616900205612\n",
      "Batch: 1800, Avg. Loss: 0.1541861492395401\n",
      "Batch: 1900, Avg. Loss: 0.15420470416545867\n",
      "[29.339 secs] Epoch: 37/100, Training loss: 0.1537902228069037\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15391038075089455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg. Loss: 0.15409815564751625\n",
      "Batch: 300, Avg. Loss: 0.15298907071352005\n",
      "Batch: 400, Avg. Loss: 0.15383588433265685\n",
      "Batch: 500, Avg. Loss: 0.15501092240214348\n",
      "Batch: 600, Avg. Loss: 0.1536938479542732\n",
      "Batch: 700, Avg. Loss: 0.153838409781456\n",
      "Batch: 800, Avg. Loss: 0.1538931192457676\n",
      "Batch: 900, Avg. Loss: 0.15421874582767486\n",
      "Batch: 1000, Avg. Loss: 0.1543443477153778\n",
      "Batch: 1100, Avg. Loss: 0.1549333342909813\n",
      "Batch: 1200, Avg. Loss: 0.1549051833152771\n",
      "Batch: 1300, Avg. Loss: 0.15315936371684075\n",
      "Batch: 1400, Avg. Loss: 0.15436507791280746\n",
      "Batch: 1500, Avg. Loss: 0.15395511507987977\n",
      "Batch: 1600, Avg. Loss: 0.154713084846735\n",
      "Batch: 1700, Avg. Loss: 0.1541477282345295\n",
      "Batch: 1800, Avg. Loss: 0.1548214739561081\n",
      "Batch: 1900, Avg. Loss: 0.15484688431024551\n",
      "[29.426 secs] Epoch: 38/100, Training loss: 0.15421183836649238\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1543770721554756\n",
      "Batch: 200, Avg. Loss: 0.15473283872008323\n",
      "Batch: 300, Avg. Loss: 0.15443502753973007\n",
      "Batch: 400, Avg. Loss: 0.15419341549277304\n",
      "Batch: 500, Avg. Loss: 0.154974854439497\n",
      "Batch: 600, Avg. Loss: 0.1554370702803135\n",
      "Batch: 700, Avg. Loss: 0.15421763241291045\n",
      "Batch: 800, Avg. Loss: 0.15465240254998208\n",
      "Batch: 900, Avg. Loss: 0.1557235053181648\n",
      "Batch: 1000, Avg. Loss: 0.1550784070789814\n",
      "Batch: 1100, Avg. Loss: 0.1555449476838112\n",
      "Batch: 1200, Avg. Loss: 0.15427078530192376\n",
      "Batch: 1300, Avg. Loss: 0.1541423173248768\n",
      "Batch: 1400, Avg. Loss: 0.15458943605422973\n",
      "Batch: 1500, Avg. Loss: 0.15507161632180214\n",
      "Batch: 1600, Avg. Loss: 0.15555068343877793\n",
      "Batch: 1700, Avg. Loss: 0.1544531074166298\n",
      "Batch: 1800, Avg. Loss: 0.15494022488594056\n",
      "Batch: 1900, Avg. Loss: 0.15460443139076233\n",
      "[29.35 secs] Epoch: 39/100, Training loss: 0.1548009702712755\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15590389043092728\n",
      "Batch: 200, Avg. Loss: 0.15477811977267264\n",
      "Batch: 300, Avg. Loss: 0.15333737045526505\n",
      "Batch: 400, Avg. Loss: 0.15353772953152656\n",
      "Batch: 500, Avg. Loss: 0.15467319265007973\n",
      "Batch: 600, Avg. Loss: 0.15438673689961432\n",
      "Batch: 700, Avg. Loss: 0.15396379455924034\n",
      "Batch: 800, Avg. Loss: 0.15372538760304452\n",
      "Batch: 900, Avg. Loss: 0.1542970784008503\n",
      "Batch: 1000, Avg. Loss: 0.15420406699180603\n",
      "Batch: 1100, Avg. Loss: 0.15403607860207558\n",
      "Batch: 1200, Avg. Loss: 0.15405124142766\n",
      "Batch: 1300, Avg. Loss: 0.15353356122970582\n",
      "Batch: 1400, Avg. Loss: 0.15429460883140564\n",
      "Batch: 1500, Avg. Loss: 0.15341252505779265\n",
      "Batch: 1600, Avg. Loss: 0.15378490343689918\n",
      "Batch: 1700, Avg. Loss: 0.15477003157138824\n",
      "Batch: 1800, Avg. Loss: 0.15427199393510818\n",
      "Batch: 1900, Avg. Loss: 0.15294662475585938\n",
      "[29.458 secs] Epoch: 40/100, Training loss: 0.15409599027254198\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15449920251965524\n",
      "Batch: 200, Avg. Loss: 0.15441115200519562\n",
      "Batch: 300, Avg. Loss: 0.15445951476693154\n",
      "Batch: 400, Avg. Loss: 0.15443047150969505\n",
      "Batch: 500, Avg. Loss: 0.1538905395567417\n",
      "Batch: 600, Avg. Loss: 0.15332541555166246\n",
      "Batch: 700, Avg. Loss: 0.15444292813539506\n",
      "Batch: 800, Avg. Loss: 0.15287858620285988\n",
      "Batch: 900, Avg. Loss: 0.15446542635560034\n",
      "Batch: 1000, Avg. Loss: 0.15334955140948295\n",
      "Batch: 1100, Avg. Loss: 0.15353208303451538\n",
      "Batch: 1200, Avg. Loss: 0.15371741682291032\n",
      "Batch: 1300, Avg. Loss: 0.15282727688550948\n",
      "Batch: 1400, Avg. Loss: 0.15296085715293883\n",
      "Batch: 1500, Avg. Loss: 0.1542074654996395\n",
      "Batch: 1600, Avg. Loss: 0.15341753482818604\n",
      "Batch: 1700, Avg. Loss: 0.15325228244066239\n",
      "Batch: 1800, Avg. Loss: 0.1531943090260029\n",
      "Batch: 1900, Avg. Loss: 0.15269197806715964\n",
      "[29.398 secs] Epoch: 41/100, Training loss: 0.15366953599172337\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15300564959645271\n",
      "Batch: 200, Avg. Loss: 0.15388309165835382\n",
      "Batch: 300, Avg. Loss: 0.15274980023503304\n",
      "Batch: 400, Avg. Loss: 0.1532268865406513\n",
      "Batch: 500, Avg. Loss: 0.1519773980975151\n",
      "Batch: 600, Avg. Loss: 0.1531786984205246\n",
      "Batch: 700, Avg. Loss: 0.15435189247131348\n",
      "Batch: 800, Avg. Loss: 0.15241077274084092\n",
      "Batch: 900, Avg. Loss: 0.15246327474713325\n",
      "Batch: 1000, Avg. Loss: 0.15479804188013077\n",
      "Batch: 1100, Avg. Loss: 0.15255857467651368\n",
      "Batch: 1200, Avg. Loss: 0.15250301823019982\n",
      "Batch: 1300, Avg. Loss: 0.1533252589404583\n",
      "Batch: 1400, Avg. Loss: 0.15321411937475204\n",
      "Batch: 1500, Avg. Loss: 0.15343581184744834\n",
      "Batch: 1600, Avg. Loss: 0.15254119366407395\n",
      "Batch: 1700, Avg. Loss: 0.15244912788271903\n",
      "Batch: 1800, Avg. Loss: 0.15422680765390395\n",
      "Batch: 1900, Avg. Loss: 0.1526167957484722\n",
      "[29.499 secs] Epoch: 42/100, Training loss: 0.15309004963755973\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1539602717757225\n",
      "Batch: 200, Avg. Loss: 0.15321296483278274\n",
      "Batch: 300, Avg. Loss: 0.1533642566204071\n",
      "Batch: 400, Avg. Loss: 0.15262289002537727\n",
      "Batch: 500, Avg. Loss: 0.15212205722928046\n",
      "Batch: 600, Avg. Loss: 0.15210023328661917\n",
      "Batch: 700, Avg. Loss: 0.15255078062415123\n",
      "Batch: 800, Avg. Loss: 0.15286324366927148\n",
      "Batch: 900, Avg. Loss: 0.15271839186549185\n",
      "Batch: 1000, Avg. Loss: 0.15281619340181352\n",
      "Batch: 1100, Avg. Loss: 0.15208756685256958\n",
      "Batch: 1200, Avg. Loss: 0.15200257569551467\n",
      "Batch: 1300, Avg. Loss: 0.1523290231823921\n",
      "Batch: 1400, Avg. Loss: 0.152434783577919\n",
      "Batch: 1500, Avg. Loss: 0.1532258577644825\n",
      "Batch: 1600, Avg. Loss: 0.15150123909115792\n",
      "Batch: 1700, Avg. Loss: 0.15207733407616617\n",
      "Batch: 1800, Avg. Loss: 0.15157804682850837\n",
      "Batch: 1900, Avg. Loss: 0.1529247795045376\n",
      "[29.37 secs] Epoch: 43/100, Training loss: 0.15253920840173807\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15437596261501313\n",
      "Batch: 200, Avg. Loss: 0.1523255367577076\n",
      "Batch: 300, Avg. Loss: 0.15335359081625938\n",
      "Batch: 400, Avg. Loss: 0.15389300614595414\n",
      "Batch: 500, Avg. Loss: 0.15248086780309678\n",
      "Batch: 600, Avg. Loss: 0.15150860205292702\n",
      "Batch: 700, Avg. Loss: 0.15226054161787034\n",
      "Batch: 800, Avg. Loss: 0.15213583648204804\n",
      "Batch: 900, Avg. Loss: 0.15398211821913718\n",
      "Batch: 1000, Avg. Loss: 0.15231703996658325\n",
      "Batch: 1100, Avg. Loss: 0.1527020038664341\n",
      "Batch: 1200, Avg. Loss: 0.15256218627095222\n",
      "Batch: 1300, Avg. Loss: 0.15240749448537827\n",
      "Batch: 1400, Avg. Loss: 0.1527942469716072\n",
      "Batch: 1500, Avg. Loss: 0.1520905627310276\n",
      "Batch: 1600, Avg. Loss: 0.15372445061802864\n",
      "Batch: 1700, Avg. Loss: 0.15176223546266557\n",
      "Batch: 1800, Avg. Loss: 0.15215911135077476\n",
      "Batch: 1900, Avg. Loss: 0.15306345462799073\n",
      "[29.432 secs] Epoch: 44/100, Training loss: 0.1527633959906006\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15240813180804252\n",
      "Batch: 200, Avg. Loss: 0.15280458718538284\n",
      "Batch: 300, Avg. Loss: 0.15127311244606972\n",
      "Batch: 400, Avg. Loss: 0.15196151584386824\n",
      "Batch: 500, Avg. Loss: 0.15239737689495086\n",
      "Batch: 600, Avg. Loss: 0.15197110757231713\n",
      "Batch: 700, Avg. Loss: 0.15344629988074301\n",
      "Batch: 800, Avg. Loss: 0.15267175167798996\n",
      "Batch: 900, Avg. Loss: 0.15280381917953492\n",
      "Batch: 1000, Avg. Loss: 0.15185147404670715\n",
      "Batch: 1100, Avg. Loss: 0.15159198641777039\n",
      "Batch: 1200, Avg. Loss: 0.1527451628446579\n",
      "Batch: 1300, Avg. Loss: 0.15243561074137688\n",
      "Batch: 1400, Avg. Loss: 0.15200097769498824\n",
      "Batch: 1500, Avg. Loss: 0.15124712884426117\n",
      "Batch: 1600, Avg. Loss: 0.15216678634285927\n",
      "Batch: 1700, Avg. Loss: 0.15250079497694968\n",
      "Batch: 1800, Avg. Loss: 0.15145973175764083\n",
      "Batch: 1900, Avg. Loss: 0.15284824684262277\n",
      "[29.374 secs] Epoch: 45/100, Training loss: 0.15220187919380232\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15161724284291267\n",
      "Batch: 200, Avg. Loss: 0.15174517616629601\n",
      "Batch: 300, Avg. Loss: 0.15091323584318161\n",
      "Batch: 400, Avg. Loss: 0.15098827347159385\n",
      "Batch: 500, Avg. Loss: 0.1510388496518135\n",
      "Batch: 600, Avg. Loss: 0.15190579429268836\n",
      "Batch: 700, Avg. Loss: 0.15189104557037353\n",
      "Batch: 800, Avg. Loss: 0.15148846581578254\n",
      "Batch: 900, Avg. Loss: 0.1516949199140072\n",
      "Batch: 1000, Avg. Loss: 0.152242301851511\n",
      "Batch: 1100, Avg. Loss: 0.15137597858905794\n",
      "Batch: 1200, Avg. Loss: 0.15177258267998694\n",
      "Batch: 1300, Avg. Loss: 0.15245992362499236\n",
      "Batch: 1400, Avg. Loss: 0.15092172369360923\n",
      "Batch: 1500, Avg. Loss: 0.15191362917423248\n",
      "Batch: 1600, Avg. Loss: 0.15244339197874068\n",
      "Batch: 1700, Avg. Loss: 0.15189637288451194\n",
      "Batch: 1800, Avg. Loss: 0.15122685953974724\n",
      "Batch: 1900, Avg. Loss: 0.1527126443386078\n",
      "[29.389 secs] Epoch: 46/100, Training loss: 0.1517336209406628\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15170576721429824\n",
      "Batch: 200, Avg. Loss: 0.15170694053173064\n",
      "Batch: 300, Avg. Loss: 0.15171655014157295\n",
      "Batch: 400, Avg. Loss: 0.15087534978985787\n",
      "Batch: 500, Avg. Loss: 0.15119466334581375\n",
      "Batch: 600, Avg. Loss: 0.15234291985630988\n",
      "Batch: 700, Avg. Loss: 0.152694261521101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 800, Avg. Loss: 0.15065568760037423\n",
      "Batch: 900, Avg. Loss: 0.15224724069237708\n",
      "Batch: 1000, Avg. Loss: 0.15177905648946763\n",
      "Batch: 1100, Avg. Loss: 0.15118886575102805\n",
      "Batch: 1200, Avg. Loss: 0.15119737684726714\n",
      "Batch: 1300, Avg. Loss: 0.1508534862101078\n",
      "Batch: 1400, Avg. Loss: 0.15208930045366287\n",
      "Batch: 1500, Avg. Loss: 0.1529301756620407\n",
      "Batch: 1600, Avg. Loss: 0.15213790237903596\n",
      "Batch: 1700, Avg. Loss: 0.1510130701959133\n",
      "Batch: 1800, Avg. Loss: 0.15082744613289834\n",
      "Batch: 1900, Avg. Loss: 0.15184221297502518\n",
      "[29.344 secs] Epoch: 47/100, Training loss: 0.1516592390873415\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15275023847818375\n",
      "Batch: 200, Avg. Loss: 0.1511467120051384\n",
      "Batch: 300, Avg. Loss: 0.15219488859176636\n",
      "Batch: 400, Avg. Loss: 0.15258598282933236\n",
      "Batch: 500, Avg. Loss: 0.1519192935526371\n",
      "Batch: 600, Avg. Loss: 0.1523231792449951\n",
      "Batch: 700, Avg. Loss: 0.15203189983963966\n",
      "Batch: 800, Avg. Loss: 0.15116812586784362\n",
      "Batch: 900, Avg. Loss: 0.1518498745560646\n",
      "Batch: 1000, Avg. Loss: 0.15108843475580216\n",
      "Batch: 1100, Avg. Loss: 0.1518373502790928\n",
      "Batch: 1200, Avg. Loss: 0.15352653682231904\n",
      "Batch: 1300, Avg. Loss: 0.15174033910036086\n",
      "Batch: 1400, Avg. Loss: 0.15204378738999366\n",
      "Batch: 1500, Avg. Loss: 0.15128226146101953\n",
      "Batch: 1600, Avg. Loss: 0.1516006773710251\n",
      "Batch: 1700, Avg. Loss: 0.15191564112901687\n",
      "Batch: 1800, Avg. Loss: 0.1519513663649559\n",
      "Batch: 1900, Avg. Loss: 0.15079663470387458\n",
      "[29.42 secs] Epoch: 48/100, Training loss: 0.15189395443047327\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15246439829468728\n",
      "Batch: 200, Avg. Loss: 0.1519069628417492\n",
      "Batch: 300, Avg. Loss: 0.15099867686629295\n",
      "Batch: 400, Avg. Loss: 0.15303658768534661\n",
      "Batch: 500, Avg. Loss: 0.152514571249485\n",
      "Batch: 600, Avg. Loss: 0.1516265508532524\n",
      "Batch: 700, Avg. Loss: 0.15170011937618255\n",
      "Batch: 800, Avg. Loss: 0.1513422140479088\n",
      "Batch: 900, Avg. Loss: 0.15133457213640214\n",
      "Batch: 1000, Avg. Loss: 0.15208771973848342\n",
      "Batch: 1100, Avg. Loss: 0.15191490545868874\n",
      "Batch: 1200, Avg. Loss: 0.15173953905701637\n",
      "Batch: 1300, Avg. Loss: 0.1513376733660698\n",
      "Batch: 1400, Avg. Loss: 0.15203056558966638\n",
      "Batch: 1500, Avg. Loss: 0.1521384121477604\n",
      "Batch: 1600, Avg. Loss: 0.15216081336140633\n",
      "Batch: 1700, Avg. Loss: 0.15089451104402543\n",
      "Batch: 1800, Avg. Loss: 0.1511831960082054\n",
      "Batch: 1900, Avg. Loss: 0.15112505003809928\n",
      "[29.465 secs] Epoch: 49/100, Training loss: 0.15173413630426236\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15094945773482324\n",
      "Batch: 200, Avg. Loss: 0.15075610727071762\n",
      "Batch: 300, Avg. Loss: 0.15090486377477647\n",
      "Batch: 400, Avg. Loss: 0.15150225177407264\n",
      "Batch: 500, Avg. Loss: 0.15032902985811233\n",
      "Batch: 600, Avg. Loss: 0.15061376512050628\n",
      "Batch: 700, Avg. Loss: 0.15210436090826987\n",
      "Batch: 800, Avg. Loss: 0.1524646933376789\n",
      "Batch: 900, Avg. Loss: 0.15121696546673774\n",
      "Batch: 1000, Avg. Loss: 0.151529503762722\n",
      "Batch: 1100, Avg. Loss: 0.15093775361776351\n",
      "Batch: 1200, Avg. Loss: 0.1503664392232895\n",
      "Batch: 1300, Avg. Loss: 0.15193959906697274\n",
      "Batch: 1400, Avg. Loss: 0.1516056777536869\n",
      "Batch: 1500, Avg. Loss: 0.15221025571227073\n",
      "Batch: 1600, Avg. Loss: 0.15163807496428489\n",
      "Batch: 1700, Avg. Loss: 0.15174084395170212\n",
      "Batch: 1800, Avg. Loss: 0.15165586084127425\n",
      "Batch: 1900, Avg. Loss: 0.1509900262951851\n",
      "[29.373 secs] Epoch: 50/100, Training loss: 0.15134478199506368\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1523142585158348\n",
      "Batch: 200, Avg. Loss: 0.15106008753180503\n",
      "Batch: 300, Avg. Loss: 0.15056480526924132\n",
      "Batch: 400, Avg. Loss: 0.15088880211114883\n",
      "Batch: 500, Avg. Loss: 0.15139894887804986\n",
      "Batch: 600, Avg. Loss: 0.15226587668061256\n",
      "Batch: 700, Avg. Loss: 0.15234799802303314\n",
      "Batch: 800, Avg. Loss: 0.15056706890463828\n",
      "Batch: 900, Avg. Loss: 0.15083834528923035\n",
      "Batch: 1000, Avg. Loss: 0.15203041598200798\n",
      "Batch: 1100, Avg. Loss: 0.15196814626455307\n",
      "Batch: 1200, Avg. Loss: 0.15269539400935173\n",
      "Batch: 1300, Avg. Loss: 0.15144877433776854\n",
      "Batch: 1400, Avg. Loss: 0.15154906317591668\n",
      "Batch: 1500, Avg. Loss: 0.15214787662029267\n",
      "Batch: 1600, Avg. Loss: 0.15204256385564804\n",
      "Batch: 1700, Avg. Loss: 0.15163204416632653\n",
      "Batch: 1800, Avg. Loss: 0.15141704082489013\n",
      "Batch: 1900, Avg. Loss: 0.1504279588162899\n",
      "[29.385 secs] Epoch: 51/100, Training loss: 0.15154932027524423\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15117245882749558\n",
      "Batch: 200, Avg. Loss: 0.15053759053349494\n",
      "Batch: 300, Avg. Loss: 0.15054435938596725\n",
      "Batch: 400, Avg. Loss: 0.15155185267329216\n",
      "Batch: 500, Avg. Loss: 0.151013280749321\n",
      "Batch: 600, Avg. Loss: 0.15043628975749015\n",
      "Batch: 700, Avg. Loss: 0.15118903011083604\n",
      "Batch: 800, Avg. Loss: 0.15205248400568963\n",
      "Batch: 900, Avg. Loss: 0.1507867631316185\n",
      "Batch: 1000, Avg. Loss: 0.15068062469363214\n",
      "Batch: 1100, Avg. Loss: 0.15052224099636077\n",
      "Batch: 1200, Avg. Loss: 0.1510249623656273\n",
      "Batch: 1300, Avg. Loss: 0.15111227944493294\n",
      "Batch: 1400, Avg. Loss: 0.15212221637368203\n",
      "Batch: 1500, Avg. Loss: 0.15066444456577302\n",
      "Batch: 1600, Avg. Loss: 0.15224676728248596\n",
      "Batch: 1700, Avg. Loss: 0.15259557500481605\n",
      "Batch: 1800, Avg. Loss: 0.15114357128739356\n",
      "Batch: 1900, Avg. Loss: 0.1506518852710724\n",
      "[29.422 secs] Epoch: 52/100, Training loss: 0.15116066005969364\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15253200203180314\n",
      "Batch: 200, Avg. Loss: 0.15115898698568345\n",
      "Batch: 300, Avg. Loss: 0.1507839135825634\n",
      "Batch: 400, Avg. Loss: 0.1512964954972267\n",
      "Batch: 500, Avg. Loss: 0.15101825520396234\n",
      "Batch: 600, Avg. Loss: 0.15138900592923166\n",
      "Batch: 700, Avg. Loss: 0.15100904047489166\n",
      "Batch: 800, Avg. Loss: 0.1511579330265522\n",
      "Batch: 900, Avg. Loss: 0.15087233021855354\n",
      "Batch: 1000, Avg. Loss: 0.15068514615297318\n",
      "Batch: 1100, Avg. Loss: 0.15232957884669304\n",
      "Batch: 1200, Avg. Loss: 0.1504549852013588\n",
      "Batch: 1300, Avg. Loss: 0.15097474053502083\n",
      "Batch: 1400, Avg. Loss: 0.14941598743200302\n",
      "Batch: 1500, Avg. Loss: 0.15046134144067763\n",
      "Batch: 1600, Avg. Loss: 0.15085528686642646\n",
      "Batch: 1700, Avg. Loss: 0.1509649248421192\n",
      "Batch: 1800, Avg. Loss: 0.15115126848220825\n",
      "Batch: 1900, Avg. Loss: 0.15033853620290757\n",
      "[29.392 secs] Epoch: 53/100, Training loss: 0.15103872494053328\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15091899529099465\n",
      "Batch: 200, Avg. Loss: 0.1504139618575573\n",
      "Batch: 300, Avg. Loss: 0.15141242280602454\n",
      "Batch: 400, Avg. Loss: 0.15110809251666069\n",
      "Batch: 500, Avg. Loss: 0.1503285437822342\n",
      "Batch: 600, Avg. Loss: 0.150713652074337\n",
      "Batch: 700, Avg. Loss: 0.1515130153298378\n",
      "Batch: 800, Avg. Loss: 0.1508780165016651\n",
      "Batch: 900, Avg. Loss: 0.15175699919462204\n",
      "Batch: 1000, Avg. Loss: 0.15061477318406105\n",
      "Batch: 1100, Avg. Loss: 0.1504374225437641\n",
      "Batch: 1200, Avg. Loss: 0.15167787328362464\n",
      "Batch: 1300, Avg. Loss: 0.15205059230327606\n",
      "Batch: 1400, Avg. Loss: 0.15129111513495444\n",
      "Batch: 1500, Avg. Loss: 0.1507931424677372\n",
      "Batch: 1600, Avg. Loss: 0.15139948412775994\n",
      "Batch: 1700, Avg. Loss: 0.15105564028024673\n",
      "Batch: 1800, Avg. Loss: 0.15028148993849755\n",
      "Batch: 1900, Avg. Loss: 0.15081418067216873\n",
      "[29.358 secs] Epoch: 54/100, Training loss: 0.1510106646126954\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1514231875538826\n",
      "Batch: 200, Avg. Loss: 0.15048609629273416\n",
      "Batch: 300, Avg. Loss: 0.15140472188591958\n",
      "Batch: 400, Avg. Loss: 0.15100203976035118\n",
      "Batch: 500, Avg. Loss: 0.15077888771891593\n",
      "Batch: 600, Avg. Loss: 0.15112950757145882\n",
      "Batch: 700, Avg. Loss: 0.15136437341570855\n",
      "Batch: 800, Avg. Loss: 0.15055051058530808\n",
      "Batch: 900, Avg. Loss: 0.1513341473042965\n",
      "Batch: 1000, Avg. Loss: 0.15131456330418586\n",
      "Batch: 1100, Avg. Loss: 0.15028634771704674\n",
      "Batch: 1200, Avg. Loss: 0.15116668343544007\n",
      "Batch: 1300, Avg. Loss: 0.1499285516142845\n",
      "Batch: 1400, Avg. Loss: 0.1506471388041973\n",
      "Batch: 1500, Avg. Loss: 0.152023523747921\n",
      "Batch: 1600, Avg. Loss: 0.1510109569132328\n",
      "Batch: 1700, Avg. Loss: 0.1517060248553753\n",
      "Batch: 1800, Avg. Loss: 0.15079985678195953\n",
      "Batch: 1900, Avg. Loss: 0.15225491508841515\n",
      "[29.38 secs] Epoch: 55/100, Training loss: 0.1511050293654844\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15303861051797868\n",
      "Batch: 200, Avg. Loss: 0.1521695902943611\n",
      "Batch: 300, Avg. Loss: 0.1507623514533043\n",
      "Batch: 400, Avg. Loss: 0.1507929500937462\n",
      "Batch: 500, Avg. Loss: 0.15090325877070426\n",
      "Batch: 600, Avg. Loss: 0.1502711582183838\n",
      "Batch: 700, Avg. Loss: 0.1506413146853447\n",
      "Batch: 800, Avg. Loss: 0.1518663428723812\n",
      "Batch: 900, Avg. Loss: 0.15183847591280938\n",
      "Batch: 1000, Avg. Loss: 0.15145458698272704\n",
      "Batch: 1100, Avg. Loss: 0.1517473988234997\n",
      "Batch: 1200, Avg. Loss: 0.15149836599826813\n",
      "Batch: 1300, Avg. Loss: 0.15124274536967278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1400, Avg. Loss: 0.1505543890595436\n",
      "Batch: 1500, Avg. Loss: 0.1518213430047035\n",
      "Batch: 1600, Avg. Loss: 0.1513649246096611\n",
      "Batch: 1700, Avg. Loss: 0.1510666672885418\n",
      "Batch: 1800, Avg. Loss: 0.15080695420503618\n",
      "Batch: 1900, Avg. Loss: 0.15028389245271684\n",
      "[29.419 secs] Epoch: 56/100, Training loss: 0.1512160452279122\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1502380068600178\n",
      "Batch: 200, Avg. Loss: 0.15018618673086168\n",
      "Batch: 300, Avg. Loss: 0.15052672505378722\n",
      "Batch: 400, Avg. Loss: 0.14999316915869712\n",
      "Batch: 500, Avg. Loss: 0.15081124886870384\n",
      "Batch: 600, Avg. Loss: 0.14984161004424096\n",
      "Batch: 700, Avg. Loss: 0.14958956107497215\n",
      "Batch: 800, Avg. Loss: 0.14941147178411485\n",
      "Batch: 900, Avg. Loss: 0.1510418574512005\n",
      "Batch: 1000, Avg. Loss: 0.15085195660591125\n",
      "Batch: 1100, Avg. Loss: 0.15204399228096008\n",
      "Batch: 1200, Avg. Loss: 0.1503410156071186\n",
      "Batch: 1300, Avg. Loss: 0.15226784631609916\n",
      "Batch: 1400, Avg. Loss: 0.15086492151021957\n",
      "Batch: 1500, Avg. Loss: 0.149710513651371\n",
      "Batch: 1600, Avg. Loss: 0.15131430730223655\n",
      "Batch: 1700, Avg. Loss: 0.15109512388706206\n",
      "Batch: 1800, Avg. Loss: 0.15140183553099631\n",
      "Batch: 1900, Avg. Loss: 0.15195668250322342\n",
      "[29.366 secs] Epoch: 57/100, Training loss: 0.15070164973867586\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15108464211225509\n",
      "Batch: 200, Avg. Loss: 0.15137336850166322\n",
      "Batch: 300, Avg. Loss: 0.15079651430249214\n",
      "Batch: 400, Avg. Loss: 0.15068060502409936\n",
      "Batch: 500, Avg. Loss: 0.15139659583568574\n",
      "Batch: 600, Avg. Loss: 0.15082314491271973\n",
      "Batch: 700, Avg. Loss: 0.1511460894346237\n",
      "Batch: 800, Avg. Loss: 0.15038783326745034\n",
      "Batch: 900, Avg. Loss: 0.15127468034625052\n",
      "Batch: 1000, Avg. Loss: 0.15064552828669547\n",
      "Batch: 1100, Avg. Loss: 0.15045609071850777\n",
      "Batch: 1200, Avg. Loss: 0.1514214040338993\n",
      "Batch: 1300, Avg. Loss: 0.15128253057599067\n",
      "Batch: 1400, Avg. Loss: 0.15143819004297257\n",
      "Batch: 1500, Avg. Loss: 0.14993058815598487\n",
      "Batch: 1600, Avg. Loss: 0.15095920622348785\n",
      "Batch: 1700, Avg. Loss: 0.15137248247861862\n",
      "Batch: 1800, Avg. Loss: 0.149629425406456\n",
      "Batch: 1900, Avg. Loss: 0.15108920097351075\n",
      "[29.347 secs] Epoch: 58/100, Training loss: 0.15092905357617317\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15123536571860313\n",
      "Batch: 200, Avg. Loss: 0.15168385758996009\n",
      "Batch: 300, Avg. Loss: 0.15177761495113373\n",
      "Batch: 400, Avg. Loss: 0.1513007651269436\n",
      "Batch: 500, Avg. Loss: 0.15055398061871528\n",
      "Batch: 600, Avg. Loss: 0.15047356620430946\n",
      "Batch: 700, Avg. Loss: 0.15085539013147353\n",
      "Batch: 800, Avg. Loss: 0.15062967762351037\n",
      "Batch: 900, Avg. Loss: 0.15056285500526428\n",
      "Batch: 1000, Avg. Loss: 0.151471548974514\n",
      "Batch: 1100, Avg. Loss: 0.15089475721120835\n",
      "Batch: 1200, Avg. Loss: 0.15152912482619285\n",
      "Batch: 1300, Avg. Loss: 0.15111486107110977\n",
      "Batch: 1400, Avg. Loss: 0.15025809094309805\n",
      "Batch: 1500, Avg. Loss: 0.15109505325555803\n",
      "Batch: 1600, Avg. Loss: 0.15197566419839859\n",
      "Batch: 1700, Avg. Loss: 0.15016792833805084\n",
      "Batch: 1800, Avg. Loss: 0.1509583806991577\n",
      "Batch: 1900, Avg. Loss: 0.1512986172735691\n",
      "[29.43 secs] Epoch: 59/100, Training loss: 0.15108484605531244\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1521141031384468\n",
      "Batch: 200, Avg. Loss: 0.1501496560871601\n",
      "Batch: 300, Avg. Loss: 0.15181397244334222\n",
      "Batch: 400, Avg. Loss: 0.14993397623300553\n",
      "Batch: 500, Avg. Loss: 0.15127449572086335\n",
      "Batch: 600, Avg. Loss: 0.15183227106928826\n",
      "Batch: 700, Avg. Loss: 0.15084644690155982\n",
      "Batch: 800, Avg. Loss: 0.15663958892226218\n",
      "Batch: 900, Avg. Loss: 0.15527543500065805\n",
      "Batch: 1000, Avg. Loss: 0.15303736612200736\n",
      "Batch: 1100, Avg. Loss: 0.1502590796351433\n",
      "Batch: 1200, Avg. Loss: 0.1506788846850395\n",
      "Batch: 1300, Avg. Loss: 0.15044110402464866\n",
      "Batch: 1400, Avg. Loss: 0.15069348484277725\n",
      "Batch: 1500, Avg. Loss: 0.15112648651003838\n",
      "Batch: 1600, Avg. Loss: 0.1516340497136116\n",
      "Batch: 1700, Avg. Loss: 0.1509266872704029\n",
      "Batch: 1800, Avg. Loss: 0.15040152370929719\n",
      "Batch: 1900, Avg. Loss: 0.15074561178684234\n",
      "[29.425 secs] Epoch: 60/100, Training loss: 0.15159018614549596\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15150418177247046\n",
      "Batch: 200, Avg. Loss: 0.1498248091340065\n",
      "Batch: 300, Avg. Loss: 0.15088257417082787\n",
      "Batch: 400, Avg. Loss: 0.1503500984609127\n",
      "Batch: 500, Avg. Loss: 0.15111509174108506\n",
      "Batch: 600, Avg. Loss: 0.15114152804017067\n",
      "Batch: 700, Avg. Loss: 0.15035418689250946\n",
      "Batch: 800, Avg. Loss: 0.15238967776298523\n",
      "Batch: 900, Avg. Loss: 0.15104571163654326\n",
      "Batch: 1000, Avg. Loss: 0.15161440193653106\n",
      "Batch: 1100, Avg. Loss: 0.15205701902508736\n",
      "Batch: 1200, Avg. Loss: 0.15233030259609223\n",
      "Batch: 1300, Avg. Loss: 0.15069958046078683\n",
      "Batch: 1400, Avg. Loss: 0.15147192388772965\n",
      "Batch: 1500, Avg. Loss: 0.1518825201690197\n",
      "Batch: 1600, Avg. Loss: 0.15164096146821976\n",
      "Batch: 1700, Avg. Loss: 0.15201276674866676\n",
      "Batch: 1800, Avg. Loss: 0.1509292307496071\n",
      "Batch: 1900, Avg. Loss: 0.1519018206000328\n",
      "[29.332 secs] Epoch: 61/100, Training loss: 0.15129276068391184\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15026652932167053\n",
      "Batch: 200, Avg. Loss: 0.15104808807373046\n",
      "Batch: 300, Avg. Loss: 0.15121314644813538\n",
      "Batch: 400, Avg. Loss: 0.15173822671175002\n",
      "Batch: 500, Avg. Loss: 0.15284808099269867\n",
      "Batch: 600, Avg. Loss: 0.15155033856630326\n",
      "Batch: 700, Avg. Loss: 0.15074789881706238\n",
      "Batch: 800, Avg. Loss: 0.15090199545025826\n",
      "Batch: 900, Avg. Loss: 0.1525903309881687\n",
      "Batch: 1000, Avg. Loss: 0.15324179127812385\n",
      "Batch: 1100, Avg. Loss: 0.15040372356772422\n",
      "Batch: 1200, Avg. Loss: 0.15032575115561486\n",
      "Batch: 1300, Avg. Loss: 0.15130322068929672\n",
      "Batch: 1400, Avg. Loss: 0.15189050257205963\n",
      "Batch: 1500, Avg. Loss: 0.1518208596110344\n",
      "Batch: 1600, Avg. Loss: 0.15201293498277665\n",
      "Batch: 1700, Avg. Loss: 0.1502610318362713\n",
      "Batch: 1800, Avg. Loss: 0.1518406942486763\n",
      "Batch: 1900, Avg. Loss: 0.15094382897019387\n",
      "[29.343 secs] Epoch: 62/100, Training loss: 0.15138471189852015\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15171008095145225\n",
      "Batch: 200, Avg. Loss: 0.15127228662371636\n",
      "Batch: 300, Avg. Loss: 0.15015178978443144\n",
      "Batch: 400, Avg. Loss: 0.1516515040397644\n",
      "Batch: 500, Avg. Loss: 0.14983708754181863\n",
      "Batch: 600, Avg. Loss: 0.1504058761894703\n",
      "Batch: 700, Avg. Loss: 0.15052088022232055\n",
      "Batch: 800, Avg. Loss: 0.1516401329636574\n",
      "Batch: 900, Avg. Loss: 0.15167351365089415\n",
      "Batch: 1000, Avg. Loss: 0.14997487023472786\n",
      "Batch: 1100, Avg. Loss: 0.15081266552209854\n",
      "Batch: 1200, Avg. Loss: 0.15018684640526772\n",
      "Batch: 1300, Avg. Loss: 0.15312800019979478\n",
      "Batch: 1400, Avg. Loss: 0.15187784537672996\n",
      "Batch: 1500, Avg. Loss: 0.15098646119236947\n",
      "Batch: 1600, Avg. Loss: 0.15080134555697441\n",
      "Batch: 1700, Avg. Loss: 0.1514612340927124\n",
      "Batch: 1800, Avg. Loss: 0.15111416339874267\n",
      "Batch: 1900, Avg. Loss: 0.15046112075448037\n",
      "[29.346 secs] Epoch: 63/100, Training loss: 0.15100698861671935\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1503456063568592\n",
      "Batch: 200, Avg. Loss: 0.15184450179338455\n",
      "Batch: 300, Avg. Loss: 0.15153396427631377\n",
      "Batch: 400, Avg. Loss: 0.15000869557261468\n",
      "Batch: 500, Avg. Loss: 0.15113922595977783\n",
      "Batch: 600, Avg. Loss: 0.15064480170607567\n",
      "Batch: 700, Avg. Loss: 0.15028752148151397\n",
      "Batch: 800, Avg. Loss: 0.15126075521111487\n",
      "Batch: 900, Avg. Loss: 0.1512235675752163\n",
      "Batch: 1000, Avg. Loss: 0.15085255071520806\n",
      "Batch: 1100, Avg. Loss: 0.15202439144253732\n",
      "Batch: 1200, Avg. Loss: 0.15194636151194574\n",
      "Batch: 1300, Avg. Loss: 0.1525801531970501\n",
      "Batch: 1400, Avg. Loss: 0.15187762022018433\n",
      "Batch: 1500, Avg. Loss: 0.15120011776685716\n",
      "Batch: 1600, Avg. Loss: 0.15145609870553017\n",
      "Batch: 1700, Avg. Loss: 0.15173007652163506\n",
      "Batch: 1800, Avg. Loss: 0.15063546791672708\n",
      "Batch: 1900, Avg. Loss: 0.15134473398327827\n",
      "[29.447 secs] Epoch: 64/100, Training loss: 0.1512644381520692\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15161131873726844\n",
      "Batch: 200, Avg. Loss: 0.15090124130249025\n",
      "Batch: 300, Avg. Loss: 0.15117935895919798\n",
      "Batch: 400, Avg. Loss: 0.15131416782736778\n",
      "Batch: 500, Avg. Loss: 0.15127000078558922\n",
      "Batch: 600, Avg. Loss: 0.15183790549635887\n",
      "Batch: 700, Avg. Loss: 0.15073989659547807\n",
      "Batch: 800, Avg. Loss: 0.15028640285134315\n",
      "Batch: 900, Avg. Loss: 0.15093382105231284\n",
      "Batch: 1000, Avg. Loss: 0.15105162754654886\n",
      "Batch: 1100, Avg. Loss: 0.1512286975979805\n",
      "Batch: 1200, Avg. Loss: 0.15178763538599013\n",
      "Batch: 1300, Avg. Loss: 0.1518143855035305\n",
      "Batch: 1400, Avg. Loss: 0.15117999598383902\n",
      "Batch: 1500, Avg. Loss: 0.15103256374597548\n",
      "Batch: 1600, Avg. Loss: 0.15156585082411766\n",
      "Batch: 1700, Avg. Loss: 0.14962927997112274\n",
      "Batch: 1800, Avg. Loss: 0.1512969848513603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1900, Avg. Loss: 0.1513286243379116\n",
      "[29.348 secs] Epoch: 65/100, Training loss: 0.15115159383175195\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1508090776205063\n",
      "Batch: 200, Avg. Loss: 0.15167398750782013\n",
      "Batch: 300, Avg. Loss: 0.151190784573555\n",
      "Batch: 400, Avg. Loss: 0.1502358441054821\n",
      "Batch: 500, Avg. Loss: 0.1506217096745968\n",
      "Batch: 600, Avg. Loss: 0.15095247343182563\n",
      "Batch: 700, Avg. Loss: 0.15079780220985411\n",
      "Batch: 800, Avg. Loss: 0.15176899269223212\n",
      "Batch: 900, Avg. Loss: 0.15173733696341515\n",
      "Batch: 1000, Avg. Loss: 0.15192886725068092\n",
      "Batch: 1100, Avg. Loss: 0.15009278669953346\n",
      "Batch: 1200, Avg. Loss: 0.15112723991274835\n",
      "Batch: 1300, Avg. Loss: 0.15159200981259346\n",
      "Batch: 1400, Avg. Loss: 0.15039573952555657\n",
      "Batch: 1500, Avg. Loss: 0.15127143561840056\n",
      "Batch: 1600, Avg. Loss: 0.1522854024171829\n",
      "Batch: 1700, Avg. Loss: 0.15200115263462066\n",
      "Batch: 1800, Avg. Loss: 0.15203972339630126\n",
      "Batch: 1900, Avg. Loss: 0.1521287153661251\n",
      "[29.368 secs] Epoch: 66/100, Training loss: 0.1513241687398728\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15123011931777\n",
      "Batch: 200, Avg. Loss: 0.15270785361528397\n",
      "Batch: 300, Avg. Loss: 0.1514340755343437\n",
      "Batch: 400, Avg. Loss: 0.15257276564836503\n",
      "Batch: 500, Avg. Loss: 0.1512486706674099\n",
      "Batch: 600, Avg. Loss: 0.1508184030652046\n",
      "Batch: 700, Avg. Loss: 0.15156166285276412\n",
      "Batch: 800, Avg. Loss: 0.1509998145699501\n",
      "Batch: 900, Avg. Loss: 0.15175329133868218\n",
      "Batch: 1000, Avg. Loss: 0.1523809726536274\n",
      "Batch: 1100, Avg. Loss: 0.15141516283154488\n",
      "Batch: 1200, Avg. Loss: 0.15017347916960716\n",
      "Batch: 1300, Avg. Loss: 0.1528834170103073\n",
      "Batch: 1400, Avg. Loss: 0.15089564457535742\n",
      "Batch: 1500, Avg. Loss: 0.1521329551935196\n",
      "Batch: 1600, Avg. Loss: 0.15186189875006675\n",
      "Batch: 1700, Avg. Loss: 0.15225277215242386\n",
      "Batch: 1800, Avg. Loss: 0.1521146720647812\n",
      "Batch: 1900, Avg. Loss: 0.15177349463105202\n",
      "[29.38 secs] Epoch: 67/100, Training loss: 0.15169502501905024\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15263126343488692\n",
      "Batch: 200, Avg. Loss: 0.15045285433530808\n",
      "Batch: 300, Avg. Loss: 0.15254236206412317\n",
      "Batch: 400, Avg. Loss: 0.15174339652061464\n",
      "Batch: 500, Avg. Loss: 0.15055780082941056\n",
      "Batch: 600, Avg. Loss: 0.15234942466020585\n",
      "Batch: 700, Avg. Loss: 0.15092968568205833\n",
      "Batch: 800, Avg. Loss: 0.15216993167996407\n",
      "Batch: 900, Avg. Loss: 0.15104473039507865\n",
      "Batch: 1000, Avg. Loss: 0.1515854036808014\n",
      "Batch: 1100, Avg. Loss: 0.15109822392463684\n",
      "Batch: 1200, Avg. Loss: 0.15214068546891213\n",
      "Batch: 1300, Avg. Loss: 0.15065839797258376\n",
      "Batch: 1400, Avg. Loss: 0.1503821775317192\n",
      "Batch: 1500, Avg. Loss: 0.15205667182803154\n",
      "Batch: 1600, Avg. Loss: 0.1518583032488823\n",
      "Batch: 1700, Avg. Loss: 0.15064629256725312\n",
      "Batch: 1800, Avg. Loss: 0.1514590409398079\n",
      "Batch: 1900, Avg. Loss: 0.15355301052331924\n",
      "[29.409 secs] Epoch: 68/100, Training loss: 0.15155254553015912\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15381568312644958\n",
      "Batch: 200, Avg. Loss: 0.15220584884285926\n",
      "Batch: 300, Avg. Loss: 0.1521466340124607\n",
      "Batch: 400, Avg. Loss: 0.15070411220192909\n",
      "Batch: 500, Avg. Loss: 0.15112601041793824\n",
      "Batch: 600, Avg. Loss: 0.15174569949507713\n",
      "Batch: 700, Avg. Loss: 0.15087233021855354\n",
      "Batch: 800, Avg. Loss: 0.1520300890505314\n",
      "Batch: 900, Avg. Loss: 0.15346794396638871\n",
      "Batch: 1000, Avg. Loss: 0.1504393571615219\n",
      "Batch: 1100, Avg. Loss: 0.1499228911101818\n",
      "Batch: 1200, Avg. Loss: 0.15302356123924254\n",
      "Batch: 1300, Avg. Loss: 0.15249002024531363\n",
      "Batch: 1400, Avg. Loss: 0.15067552611231805\n",
      "Batch: 1500, Avg. Loss: 0.1510935841500759\n",
      "Batch: 1600, Avg. Loss: 0.15128425508737564\n",
      "Batch: 1700, Avg. Loss: 0.1514037826657295\n",
      "Batch: 1800, Avg. Loss: 0.15174176394939423\n",
      "Batch: 1900, Avg. Loss: 0.15170895516872407\n",
      "[29.456 secs] Epoch: 69/100, Training loss: 0.1516259305842579\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15214598134160043\n",
      "Batch: 200, Avg. Loss: 0.15091725811362267\n",
      "Batch: 300, Avg. Loss: 0.1512549939751625\n",
      "Batch: 400, Avg. Loss: 0.15127097979187965\n",
      "Batch: 500, Avg. Loss: 0.15091759741306304\n",
      "Batch: 600, Avg. Loss: 0.15164937257766722\n",
      "Batch: 700, Avg. Loss: 0.15113417640328408\n",
      "Batch: 800, Avg. Loss: 0.1517663422226906\n",
      "Batch: 900, Avg. Loss: 0.15134728118777274\n",
      "Batch: 1000, Avg. Loss: 0.15045732080936433\n",
      "Batch: 1100, Avg. Loss: 0.15190655261278152\n",
      "Batch: 1200, Avg. Loss: 0.15362411975860596\n",
      "Batch: 1300, Avg. Loss: 0.15289790332317352\n",
      "Batch: 1400, Avg. Loss: 0.1512116825580597\n",
      "Batch: 1500, Avg. Loss: 0.1516708979010582\n",
      "Batch: 1600, Avg. Loss: 0.15200095862150192\n",
      "Batch: 1700, Avg. Loss: 0.1514901527762413\n",
      "Batch: 1800, Avg. Loss: 0.15099178969860078\n",
      "Batch: 1900, Avg. Loss: 0.15078347593545913\n",
      "[29.344 secs] Epoch: 70/100, Training loss: 0.15156098146338545\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15090716063976287\n",
      "Batch: 200, Avg. Loss: 0.15209677681326866\n",
      "Batch: 300, Avg. Loss: 0.1517079821228981\n",
      "Batch: 400, Avg. Loss: 0.15033665120601655\n",
      "Batch: 500, Avg. Loss: 0.15153694972395898\n",
      "Batch: 600, Avg. Loss: 0.15109478667378426\n",
      "Batch: 700, Avg. Loss: 0.15173320606350899\n",
      "Batch: 800, Avg. Loss: 0.15191246926784516\n",
      "Batch: 900, Avg. Loss: 0.15197072207927703\n",
      "Batch: 1000, Avg. Loss: 0.15112099334597587\n",
      "Batch: 1100, Avg. Loss: 0.15331894546747207\n",
      "Batch: 1200, Avg. Loss: 0.15190417259931566\n",
      "Batch: 1300, Avg. Loss: 0.1522233948111534\n",
      "Batch: 1400, Avg. Loss: 0.15209832176566124\n",
      "Batch: 1500, Avg. Loss: 0.15294846996665\n",
      "Batch: 1600, Avg. Loss: 0.15128245025873185\n",
      "Batch: 1700, Avg. Loss: 0.1521797901391983\n",
      "Batch: 1800, Avg. Loss: 0.151273046284914\n",
      "Batch: 1900, Avg. Loss: 0.15234031096100809\n",
      "[29.331 secs] Epoch: 71/100, Training loss: 0.15178654664706062\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1520703485608101\n",
      "Batch: 200, Avg. Loss: 0.1515197701752186\n",
      "Batch: 300, Avg. Loss: 0.1518593682348728\n",
      "Batch: 400, Avg. Loss: 0.1513629986345768\n",
      "Batch: 500, Avg. Loss: 0.15064875081181525\n",
      "Batch: 600, Avg. Loss: 0.15197046026587485\n",
      "Batch: 700, Avg. Loss: 0.1509716409444809\n",
      "Batch: 800, Avg. Loss: 0.15115411698818207\n",
      "Batch: 900, Avg. Loss: 0.15187683016061782\n",
      "Batch: 1000, Avg. Loss: 0.15190014317631723\n",
      "Batch: 1100, Avg. Loss: 0.1528292939066887\n",
      "Batch: 1200, Avg. Loss: 0.15140380859375\n",
      "Batch: 1300, Avg. Loss: 0.1519334928691387\n",
      "Batch: 1400, Avg. Loss: 0.15299776524305345\n",
      "Batch: 1500, Avg. Loss: 0.15262107327580451\n",
      "Batch: 1600, Avg. Loss: 0.15375382766127588\n",
      "Batch: 1700, Avg. Loss: 0.15515703469514847\n",
      "Batch: 1800, Avg. Loss: 0.15242537781596183\n",
      "Batch: 1900, Avg. Loss: 0.1521641443669796\n",
      "[29.464 secs] Epoch: 72/100, Training loss: 0.15213102819121604\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1527886199951172\n",
      "Batch: 200, Avg. Loss: 0.1513966578245163\n",
      "Batch: 300, Avg. Loss: 0.1506021362543106\n",
      "Batch: 400, Avg. Loss: 0.1513264212012291\n",
      "Batch: 500, Avg. Loss: 0.15105578422546387\n",
      "Batch: 600, Avg. Loss: 0.1512113966047764\n",
      "Batch: 700, Avg. Loss: 0.15122367367148398\n",
      "Batch: 800, Avg. Loss: 0.15053323969244958\n",
      "Batch: 900, Avg. Loss: 0.1513776695728302\n",
      "Batch: 1000, Avg. Loss: 0.1545732992887497\n",
      "Batch: 1100, Avg. Loss: 0.15170783340930938\n",
      "Batch: 1200, Avg. Loss: 0.15216318830847742\n",
      "Batch: 1300, Avg. Loss: 0.151672832518816\n",
      "Batch: 1400, Avg. Loss: 0.15122258067131042\n",
      "Batch: 1500, Avg. Loss: 0.15251354083418847\n",
      "Batch: 1600, Avg. Loss: 0.1513323637843132\n",
      "Batch: 1700, Avg. Loss: 0.15231498792767525\n",
      "Batch: 1800, Avg. Loss: 0.15141226530075072\n",
      "Batch: 1900, Avg. Loss: 0.15157983019948007\n",
      "[29.374 secs] Epoch: 73/100, Training loss: 0.15168740313610743\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15238586142659188\n",
      "Batch: 200, Avg. Loss: 0.15049949780106545\n",
      "Batch: 300, Avg. Loss: 0.15170329600572585\n",
      "Batch: 400, Avg. Loss: 0.1507747885584831\n",
      "Batch: 500, Avg. Loss: 0.15072367012500762\n",
      "Batch: 600, Avg. Loss: 0.1502155463397503\n",
      "Batch: 700, Avg. Loss: 0.15171022221446037\n",
      "Batch: 800, Avg. Loss: 0.15138336151838303\n",
      "Batch: 900, Avg. Loss: 0.152119280397892\n",
      "Batch: 1000, Avg. Loss: 0.15016442283988\n",
      "Batch: 1100, Avg. Loss: 0.1497645179927349\n",
      "Batch: 1200, Avg. Loss: 0.1503456275165081\n",
      "Batch: 1300, Avg. Loss: 0.1501809774339199\n",
      "Batch: 1400, Avg. Loss: 0.15165840968489647\n",
      "Batch: 1500, Avg. Loss: 0.15258785739541053\n",
      "Batch: 1600, Avg. Loss: 0.15092784598469733\n",
      "Batch: 1700, Avg. Loss: 0.15216330632567407\n",
      "Batch: 1800, Avg. Loss: 0.1514451076090336\n",
      "Batch: 1900, Avg. Loss: 0.15119626000523567\n",
      "[29.371 secs] Epoch: 74/100, Training loss: 0.15117868774226403\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15200878873467447\n",
      "Batch: 200, Avg. Loss: 0.15207672879099846\n",
      "Batch: 300, Avg. Loss: 0.15153264433145522\n",
      "Batch: 400, Avg. Loss: 0.15092742025852204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg. Loss: 0.15074440866708755\n",
      "Batch: 600, Avg. Loss: 0.15145018473267555\n",
      "Batch: 700, Avg. Loss: 0.15113261446356774\n",
      "Batch: 800, Avg. Loss: 0.15061475202441216\n",
      "Batch: 900, Avg. Loss: 0.15238463044166564\n",
      "Batch: 1000, Avg. Loss: 0.15193841233849525\n",
      "Batch: 1100, Avg. Loss: 0.15088920220732688\n",
      "Batch: 1200, Avg. Loss: 0.15050218105316163\n",
      "Batch: 1300, Avg. Loss: 0.15117825150489808\n",
      "Batch: 1400, Avg. Loss: 0.15075247138738632\n",
      "Batch: 1500, Avg. Loss: 0.1525949366390705\n",
      "Batch: 1600, Avg. Loss: 0.15159811183810235\n",
      "Batch: 1700, Avg. Loss: 0.15116813376545907\n",
      "Batch: 1800, Avg. Loss: 0.15106527060270308\n",
      "Batch: 1900, Avg. Loss: 0.15167044818401337\n",
      "[29.338 secs] Epoch: 75/100, Training loss: 0.15134832573370166\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15190708205103876\n",
      "Batch: 200, Avg. Loss: 0.15214611262083053\n",
      "Batch: 300, Avg. Loss: 0.15198185786604881\n",
      "Batch: 400, Avg. Loss: 0.15083048716187478\n",
      "Batch: 500, Avg. Loss: 0.15047059029340745\n",
      "Batch: 600, Avg. Loss: 0.14985758408904076\n",
      "Batch: 700, Avg. Loss: 0.1512151426076889\n",
      "Batch: 800, Avg. Loss: 0.15018897891044616\n",
      "Batch: 900, Avg. Loss: 0.1521747474372387\n",
      "Batch: 1000, Avg. Loss: 0.14977043092250825\n",
      "Batch: 1100, Avg. Loss: 0.15094285681843758\n",
      "Batch: 1200, Avg. Loss: 0.15057774215936662\n",
      "Batch: 1300, Avg. Loss: 0.1512293227016926\n",
      "Batch: 1400, Avg. Loss: 0.14964324489235878\n",
      "Batch: 1500, Avg. Loss: 0.1513413417339325\n",
      "Batch: 1700, Avg. Loss: 0.15049350410699844\n",
      "Batch: 1800, Avg. Loss: 0.1515812696516514\n",
      "Batch: 1900, Avg. Loss: 0.1506868851184845\n",
      "[29.391 secs] Epoch: 76/100, Training loss: 0.15089904548964456\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15085003808140754\n",
      "Batch: 200, Avg. Loss: 0.15174241214990616\n",
      "Batch: 300, Avg. Loss: 0.15136989176273347\n",
      "Batch: 400, Avg. Loss: 0.152509131282568\n",
      "Batch: 500, Avg. Loss: 0.15108331978321077\n",
      "Batch: 600, Avg. Loss: 0.15070542082190513\n",
      "Batch: 700, Avg. Loss: 0.15193201452493668\n",
      "Batch: 800, Avg. Loss: 0.15133197337388993\n",
      "Batch: 900, Avg. Loss: 0.15077111318707467\n",
      "Batch: 1000, Avg. Loss: 0.15112277150154113\n",
      "Batch: 1100, Avg. Loss: 0.15101478546857833\n",
      "Batch: 1200, Avg. Loss: 0.15117968171834945\n",
      "Batch: 1300, Avg. Loss: 0.14943177312612532\n",
      "Batch: 1400, Avg. Loss: 0.15145282581448555\n",
      "Batch: 1500, Avg. Loss: 0.1507850953936577\n",
      "Batch: 1600, Avg. Loss: 0.1505119989812374\n",
      "Batch: 1700, Avg. Loss: 0.15090964421629904\n",
      "Batch: 1800, Avg. Loss: 0.15092696353793145\n",
      "Batch: 1900, Avg. Loss: 0.1506033755838871\n",
      "[29.357 secs] Epoch: 77/100, Training loss: 0.15110667455586832\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15091165527701378\n",
      "Batch: 200, Avg. Loss: 0.15045399218797684\n",
      "Batch: 300, Avg. Loss: 0.15079550430178643\n",
      "Batch: 400, Avg. Loss: 0.15139235705137252\n",
      "Batch: 500, Avg. Loss: 0.15042277485132216\n",
      "Batch: 600, Avg. Loss: 0.1512989330291748\n",
      "Batch: 700, Avg. Loss: 0.15066108480095863\n",
      "Batch: 800, Avg. Loss: 0.1508732396364212\n",
      "Batch: 900, Avg. Loss: 0.1505255615711212\n",
      "Batch: 1000, Avg. Loss: 0.15046344354748725\n",
      "Batch: 1100, Avg. Loss: 0.1514489072561264\n",
      "Batch: 1200, Avg. Loss: 0.15083950608968735\n",
      "Batch: 1300, Avg. Loss: 0.15043986111879348\n",
      "Batch: 1400, Avg. Loss: 0.15032049983739854\n",
      "Batch: 1500, Avg. Loss: 0.1507318077981472\n",
      "Batch: 1600, Avg. Loss: 0.15059062451124192\n",
      "Batch: 1700, Avg. Loss: 0.14853736251592636\n",
      "Batch: 1800, Avg. Loss: 0.14978110238909723\n",
      "Batch: 1900, Avg. Loss: 0.15018967643380166\n",
      "[29.364 secs] Epoch: 78/100, Training loss: 0.15055709907226456\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15020266637206078\n",
      "Batch: 200, Avg. Loss: 0.15051297053694726\n",
      "Batch: 300, Avg. Loss: 0.15032752335071564\n",
      "Batch: 400, Avg. Loss: 0.1509698936343193\n",
      "Batch: 500, Avg. Loss: 0.1502125695347786\n",
      "Batch: 600, Avg. Loss: 0.1506544953584671\n",
      "Batch: 700, Avg. Loss: 0.15031177416443825\n",
      "Batch: 800, Avg. Loss: 0.1515215864777565\n",
      "Batch: 900, Avg. Loss: 0.1506982186436653\n",
      "Batch: 1000, Avg. Loss: 0.15079037711024285\n",
      "Batch: 1100, Avg. Loss: 0.15046209186315537\n",
      "Batch: 1200, Avg. Loss: 0.1513943102955818\n",
      "Batch: 1300, Avg. Loss: 0.1507975387573242\n",
      "Batch: 1400, Avg. Loss: 0.1504584513604641\n",
      "Batch: 1500, Avg. Loss: 0.150087199062109\n",
      "Batch: 1600, Avg. Loss: 0.15017727509140968\n",
      "Batch: 1700, Avg. Loss: 0.15018526569008828\n",
      "Batch: 1800, Avg. Loss: 0.15070294842123985\n",
      "Batch: 1900, Avg. Loss: 0.15011541813611984\n",
      "[29.37 secs] Epoch: 79/100, Training loss: 0.15056187651113453\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15060097962617874\n",
      "Batch: 200, Avg. Loss: 0.1490323144197464\n",
      "Batch: 300, Avg. Loss: 0.15074520081281662\n",
      "Batch: 400, Avg. Loss: 0.1501532207429409\n",
      "Batch: 500, Avg. Loss: 0.1513836733996868\n",
      "Batch: 600, Avg. Loss: 0.14892518356442452\n",
      "Batch: 700, Avg. Loss: 0.15030487418174743\n",
      "Batch: 800, Avg. Loss: 0.1500018861889839\n",
      "Batch: 900, Avg. Loss: 0.14988077372312547\n",
      "Batch: 1000, Avg. Loss: 0.15076610177755356\n",
      "Batch: 1100, Avg. Loss: 0.15012071639299393\n",
      "Batch: 1200, Avg. Loss: 0.14946261674165726\n",
      "Batch: 1300, Avg. Loss: 0.1501780232787132\n",
      "Batch: 1400, Avg. Loss: 0.1515179018676281\n",
      "Batch: 1500, Avg. Loss: 0.14949093803763389\n",
      "Batch: 1600, Avg. Loss: 0.15040821850299835\n",
      "Batch: 1700, Avg. Loss: 0.1515379624068737\n",
      "Batch: 1800, Avg. Loss: 0.1496162749826908\n",
      "Batch: 1900, Avg. Loss: 0.1497690461575985\n",
      "[29.44 secs] Epoch: 80/100, Training loss: 0.15020565599386132\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15163405120372772\n",
      "Batch: 200, Avg. Loss: 0.15004580825567246\n",
      "Batch: 300, Avg. Loss: 0.1503895603120327\n",
      "Batch: 400, Avg. Loss: 0.1499771322309971\n",
      "Batch: 500, Avg. Loss: 0.14947031199932098\n",
      "Batch: 600, Avg. Loss: 0.15011537328362465\n",
      "Batch: 700, Avg. Loss: 0.15010862350463866\n",
      "Batch: 800, Avg. Loss: 0.1514517204463482\n",
      "Batch: 900, Avg. Loss: 0.15017864614725113\n",
      "Batch: 1000, Avg. Loss: 0.15060141205787658\n",
      "Batch: 1100, Avg. Loss: 0.1508960935473442\n",
      "Batch: 1200, Avg. Loss: 0.1491461516916752\n",
      "Batch: 1300, Avg. Loss: 0.14911324188113212\n",
      "Batch: 1400, Avg. Loss: 0.1495429815351963\n",
      "Batch: 1500, Avg. Loss: 0.1505286830663681\n",
      "Batch: 1600, Avg. Loss: 0.15096802562475203\n",
      "Batch: 1700, Avg. Loss: 0.15099722981452943\n",
      "Batch: 1800, Avg. Loss: 0.14884215071797371\n",
      "Batch: 1900, Avg. Loss: 0.15020410865545272\n",
      "[29.387 secs] Epoch: 81/100, Training loss: 0.15020082261081605\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.14954079821705818\n",
      "Batch: 200, Avg. Loss: 0.15072919696569442\n",
      "Batch: 300, Avg. Loss: 0.14944256082177163\n",
      "Batch: 400, Avg. Loss: 0.14965478509664534\n",
      "Batch: 500, Avg. Loss: 0.1493302960693836\n",
      "Batch: 600, Avg. Loss: 0.14958324834704398\n",
      "Batch: 700, Avg. Loss: 0.14984390258789063\n",
      "Batch: 800, Avg. Loss: 0.15015319988131523\n",
      "Batch: 900, Avg. Loss: 0.14968419551849366\n",
      "Batch: 1000, Avg. Loss: 0.15017494201660156\n",
      "Batch: 1100, Avg. Loss: 0.15002944588661193\n",
      "Batch: 1200, Avg. Loss: 0.15045579507946968\n",
      "Batch: 1300, Avg. Loss: 0.1501094453036785\n",
      "Batch: 1400, Avg. Loss: 0.15027838543057442\n",
      "Batch: 1500, Avg. Loss: 0.14923504695296289\n",
      "Batch: 1600, Avg. Loss: 0.1494550636410713\n",
      "Batch: 1700, Avg. Loss: 0.15041888311505316\n",
      "Batch: 1800, Avg. Loss: 0.15073227286338806\n",
      "Batch: 1900, Avg. Loss: 0.1500259231030941\n",
      "[29.355 secs] Epoch: 82/100, Training loss: 0.14996045626539778\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1505681911110878\n",
      "Batch: 200, Avg. Loss: 0.14940854474902154\n",
      "Batch: 300, Avg. Loss: 0.14975254252552986\n",
      "Batch: 400, Avg. Loss: 0.15054218962788582\n",
      "Batch: 500, Avg. Loss: 0.15011035546660423\n",
      "Batch: 600, Avg. Loss: 0.1491590791940689\n",
      "Batch: 700, Avg. Loss: 0.14927963480353357\n",
      "Batch: 800, Avg. Loss: 0.14993553340435029\n",
      "Batch: 900, Avg. Loss: 0.15068484112620353\n",
      "Batch: 1000, Avg. Loss: 0.14892725363373757\n",
      "Batch: 1100, Avg. Loss: 0.15147774130105973\n",
      "Batch: 1200, Avg. Loss: 0.14972221866250038\n",
      "Batch: 1300, Avg. Loss: 0.15036681160330773\n",
      "Batch: 1400, Avg. Loss: 0.15059703707695007\n",
      "Batch: 1500, Avg. Loss: 0.1502770258486271\n",
      "Batch: 1600, Avg. Loss: 0.14978206470608713\n",
      "Batch: 1700, Avg. Loss: 0.15006293579936028\n",
      "Batch: 1800, Avg. Loss: 0.14892508298158647\n",
      "Batch: 1900, Avg. Loss: 0.1503205692768097\n",
      "[29.355 secs] Epoch: 83/100, Training loss: 0.1499481036908307\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15062353134155274\n",
      "Batch: 200, Avg. Loss: 0.1499459359049797\n",
      "Batch: 300, Avg. Loss: 0.15104842886328698\n",
      "Batch: 400, Avg. Loss: 0.15301214948296546\n",
      "Batch: 500, Avg. Loss: 0.15211280912160874\n",
      "Batch: 600, Avg. Loss: 0.14983907490968704\n",
      "Batch: 700, Avg. Loss: 0.15125986203551292\n",
      "Batch: 800, Avg. Loss: 0.151023281365633\n",
      "Batch: 900, Avg. Loss: 0.15145330548286437\n",
      "Batch: 1000, Avg. Loss: 0.1509488432109356\n",
      "Batch: 1100, Avg. Loss: 0.15050670996308327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1200, Avg. Loss: 0.1494721594452858\n",
      "Batch: 1300, Avg. Loss: 0.15044932052493096\n",
      "Batch: 1400, Avg. Loss: 0.15062755912542344\n",
      "Batch: 1500, Avg. Loss: 0.1497802120447159\n",
      "Batch: 1600, Avg. Loss: 0.14983998998999595\n",
      "Batch: 1700, Avg. Loss: 0.14987235873937607\n",
      "Batch: 1800, Avg. Loss: 0.1510931695997715\n",
      "Batch: 1900, Avg. Loss: 0.1514621366560459\n",
      "[29.382 secs] Epoch: 84/100, Training loss: 0.15068379459385983\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15059604823589326\n",
      "Batch: 200, Avg. Loss: 0.15118030697107315\n",
      "Batch: 300, Avg. Loss: 0.15147995233535766\n",
      "Batch: 400, Avg. Loss: 0.15009935691952705\n",
      "Batch: 500, Avg. Loss: 0.14947332337498664\n",
      "Batch: 600, Avg. Loss: 0.14959409922361375\n",
      "Batch: 700, Avg. Loss: 0.15100446090102196\n",
      "Batch: 800, Avg. Loss: 0.14989247515797616\n",
      "Batch: 900, Avg. Loss: 0.14933600008487702\n",
      "Batch: 1000, Avg. Loss: 0.14942512944340705\n",
      "Batch: 1100, Avg. Loss: 0.15062185883522033\n",
      "Batch: 1200, Avg. Loss: 0.1505020585656166\n",
      "Batch: 1300, Avg. Loss: 0.14919936269521714\n",
      "Batch: 1400, Avg. Loss: 0.1504841800034046\n",
      "Batch: 1500, Avg. Loss: 0.14983271479606627\n",
      "Batch: 1600, Avg. Loss: 0.15182129830121993\n",
      "Batch: 1700, Avg. Loss: 0.14957852974534036\n",
      "Batch: 1800, Avg. Loss: 0.15066950902342796\n",
      "Batch: 1900, Avg. Loss: 0.15084227174520493\n",
      "[29.389 secs] Epoch: 85/100, Training loss: 0.15028581076598094\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15025851786136626\n",
      "Batch: 200, Avg. Loss: 0.15014761120080947\n",
      "Batch: 300, Avg. Loss: 0.14868421226739884\n",
      "Batch: 400, Avg. Loss: 0.149569251537323\n",
      "Batch: 500, Avg. Loss: 0.14883201956748962\n",
      "Batch: 600, Avg. Loss: 0.15057504191994667\n",
      "Batch: 700, Avg. Loss: 0.1502307479083538\n",
      "Batch: 800, Avg. Loss: 0.14922601491212845\n",
      "Batch: 900, Avg. Loss: 0.1502889722585678\n",
      "Batch: 1000, Avg. Loss: 0.1505991642177105\n",
      "Batch: 1100, Avg. Loss: 0.1506968332827091\n",
      "Batch: 1200, Avg. Loss: 0.15032805666327476\n",
      "Batch: 1300, Avg. Loss: 0.15120010063052178\n",
      "Batch: 1400, Avg. Loss: 0.14978466480970382\n",
      "Batch: 1500, Avg. Loss: 0.15021681413054466\n",
      "Batch: 1600, Avg. Loss: 0.15066870287060738\n",
      "Batch: 1700, Avg. Loss: 0.15043295457959174\n",
      "Batch: 1800, Avg. Loss: 0.15052218601107598\n",
      "Batch: 1900, Avg. Loss: 0.15198218509554862\n",
      "[29.326 secs] Epoch: 86/100, Training loss: 0.15023089401584078\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1520897863805294\n",
      "Batch: 200, Avg. Loss: 0.14974748983979225\n",
      "Batch: 300, Avg. Loss: 0.15032706946134566\n",
      "Batch: 400, Avg. Loss: 0.14956502139568328\n",
      "Batch: 500, Avg. Loss: 0.15059066355228423\n",
      "Batch: 600, Avg. Loss: 0.1502789632976055\n",
      "Batch: 700, Avg. Loss: 0.1512190145254135\n",
      "Batch: 800, Avg. Loss: 0.15067410811781884\n",
      "Batch: 900, Avg. Loss: 0.15110768243670464\n",
      "Batch: 1000, Avg. Loss: 0.15083179652690887\n",
      "Batch: 1100, Avg. Loss: 0.15133345380425453\n",
      "Batch: 1200, Avg. Loss: 0.15079658046364786\n",
      "Batch: 1300, Avg. Loss: 0.1500897066295147\n",
      "Batch: 1400, Avg. Loss: 0.1499471400678158\n",
      "Batch: 1500, Avg. Loss: 0.15030717402696608\n",
      "Batch: 1600, Avg. Loss: 0.15183858066797257\n",
      "Batch: 1700, Avg. Loss: 0.15124286890029906\n",
      "Batch: 1800, Avg. Loss: 0.1509414345026016\n",
      "Batch: 1900, Avg. Loss: 0.15191863000392913\n",
      "[29.319 secs] Epoch: 87/100, Training loss: 0.15079415970869903\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1514430196583271\n",
      "Batch: 200, Avg. Loss: 0.15004335314035416\n",
      "Batch: 300, Avg. Loss: 0.15149602219462394\n",
      "Batch: 400, Avg. Loss: 0.15095749005675316\n",
      "Batch: 500, Avg. Loss: 0.15074270397424697\n",
      "Batch: 600, Avg. Loss: 0.1513882274925709\n",
      "Batch: 700, Avg. Loss: 0.151397193223238\n",
      "Batch: 800, Avg. Loss: 0.15135260716080665\n",
      "Batch: 900, Avg. Loss: 0.15084240049123765\n",
      "Batch: 1000, Avg. Loss: 0.1514007368683815\n",
      "Batch: 1100, Avg. Loss: 0.15047845736145973\n",
      "Batch: 1200, Avg. Loss: 0.15118469744920732\n",
      "Batch: 1300, Avg. Loss: 0.1516836953163147\n",
      "Batch: 1400, Avg. Loss: 0.1511256568133831\n",
      "Batch: 1500, Avg. Loss: 0.15097756311297417\n",
      "Batch: 1600, Avg. Loss: 0.15061990097165107\n",
      "Batch: 1700, Avg. Loss: 0.15009065046906472\n",
      "Batch: 1800, Avg. Loss: 0.1517431490123272\n",
      "Batch: 1900, Avg. Loss: 0.15085334256291388\n",
      "[29.343 secs] Epoch: 88/100, Training loss: 0.15102915898224714\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15199995800852775\n",
      "Batch: 200, Avg. Loss: 0.1513107457756996\n",
      "Batch: 300, Avg. Loss: 0.15084375128149985\n",
      "Batch: 400, Avg. Loss: 0.15178872287273407\n",
      "Batch: 500, Avg. Loss: 0.15110475748777388\n",
      "Batch: 600, Avg. Loss: 0.15096468225121498\n",
      "Batch: 700, Avg. Loss: 0.15062597945332526\n",
      "Batch: 800, Avg. Loss: 0.1511439174413681\n",
      "Batch: 900, Avg. Loss: 0.15092796757817267\n",
      "Batch: 1000, Avg. Loss: 0.15258063971996308\n",
      "Batch: 1100, Avg. Loss: 0.15290441393852233\n",
      "Batch: 1200, Avg. Loss: 0.1514479660987854\n",
      "Batch: 1300, Avg. Loss: 0.14966172114014625\n",
      "Batch: 1400, Avg. Loss: 0.1500834259390831\n",
      "Batch: 1500, Avg. Loss: 0.15016030192375182\n",
      "Batch: 1600, Avg. Loss: 0.15077915608882905\n",
      "Batch: 1700, Avg. Loss: 0.15234294578433036\n",
      "Batch: 1800, Avg. Loss: 0.15013867273926734\n",
      "Batch: 1900, Avg. Loss: 0.15164821341633797\n",
      "[29.528 secs] Epoch: 89/100, Training loss: 0.15117252065953604\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15113527119159698\n",
      "Batch: 200, Avg. Loss: 0.15132999017834664\n",
      "Batch: 300, Avg. Loss: 0.15057606533169746\n",
      "Batch: 400, Avg. Loss: 0.15080203011631965\n",
      "Batch: 500, Avg. Loss: 0.1509931966662407\n",
      "Batch: 600, Avg. Loss: 0.15109033048152923\n",
      "Batch: 700, Avg. Loss: 0.1507502557337284\n",
      "Batch: 800, Avg. Loss: 0.1506187768280506\n",
      "Batch: 900, Avg. Loss: 0.1500764673948288\n",
      "Batch: 1000, Avg. Loss: 0.15111737355589866\n",
      "Batch: 1100, Avg. Loss: 0.15041927397251129\n",
      "Batch: 1200, Avg. Loss: 0.1499175299704075\n",
      "Batch: 1300, Avg. Loss: 0.1505891638994217\n",
      "Batch: 1400, Avg. Loss: 0.15129463747143745\n",
      "Batch: 1500, Avg. Loss: 0.15016209244728088\n",
      "Batch: 1600, Avg. Loss: 0.15056486189365387\n",
      "Batch: 1700, Avg. Loss: 0.15071798130869865\n",
      "Batch: 1800, Avg. Loss: 0.1506296454370022\n",
      "Batch: 1900, Avg. Loss: 0.15096156880259515\n",
      "[29.373 secs] Epoch: 90/100, Training loss: 0.15072730261386355\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15172697946429253\n",
      "Batch: 200, Avg. Loss: 0.1518230739235878\n",
      "Batch: 300, Avg. Loss: 0.14988900005817413\n",
      "Batch: 400, Avg. Loss: 0.15029194101691246\n",
      "Batch: 500, Avg. Loss: 0.15064996153116225\n",
      "Batch: 600, Avg. Loss: 0.1505318297445774\n",
      "Batch: 700, Avg. Loss: 0.1503703273832798\n",
      "Batch: 800, Avg. Loss: 0.14986459493637086\n",
      "Batch: 900, Avg. Loss: 0.1492094300687313\n",
      "Batch: 1000, Avg. Loss: 0.1494418416917324\n",
      "Batch: 1100, Avg. Loss: 0.1506072273850441\n",
      "Batch: 1200, Avg. Loss: 0.15124221980571748\n",
      "Batch: 1300, Avg. Loss: 0.14988824859261513\n",
      "Batch: 1400, Avg. Loss: 0.15172165289521217\n",
      "Batch: 1500, Avg. Loss: 0.14913043469190598\n",
      "Batch: 1600, Avg. Loss: 0.15065567657351495\n",
      "Batch: 1700, Avg. Loss: 0.1510070015490055\n",
      "Batch: 1800, Avg. Loss: 0.15052584528923035\n",
      "Batch: 1900, Avg. Loss: 0.15077139899134637\n",
      "[29.357 secs] Epoch: 91/100, Training loss: 0.15045646285235942\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15067896232008934\n",
      "Batch: 200, Avg. Loss: 0.15112023308873176\n",
      "Batch: 300, Avg. Loss: 0.14937152355909347\n",
      "Batch: 400, Avg. Loss: 0.15033364847302436\n",
      "Batch: 500, Avg. Loss: 0.15093616783618927\n",
      "Batch: 600, Avg. Loss: 0.14950257927179336\n",
      "Batch: 700, Avg. Loss: 0.15032128289341926\n",
      "Batch: 800, Avg. Loss: 0.15089503958821296\n",
      "Batch: 900, Avg. Loss: 0.1502535454928875\n",
      "Batch: 1000, Avg. Loss: 0.14930139288306235\n",
      "Batch: 1100, Avg. Loss: 0.15047242760658264\n",
      "Batch: 1200, Avg. Loss: 0.14966823801398277\n",
      "Batch: 1300, Avg. Loss: 0.14996078118681908\n",
      "Batch: 1400, Avg. Loss: 0.15057686373591422\n",
      "Batch: 1500, Avg. Loss: 0.14887629076838493\n",
      "Batch: 1600, Avg. Loss: 0.14941864132881164\n",
      "Batch: 1700, Avg. Loss: 0.14965288937091828\n",
      "Batch: 1800, Avg. Loss: 0.14979461431503296\n",
      "Batch: 1900, Avg. Loss: 0.149780063778162\n",
      "[29.347 secs] Epoch: 92/100, Training loss: 0.1500554367091541\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.1496036821603775\n",
      "Batch: 200, Avg. Loss: 0.15027670711278915\n",
      "Batch: 300, Avg. Loss: 0.1505944775044918\n",
      "Batch: 400, Avg. Loss: 0.14923458352684973\n",
      "Batch: 500, Avg. Loss: 0.14917313277721406\n",
      "Batch: 600, Avg. Loss: 0.1494464547932148\n",
      "Batch: 700, Avg. Loss: 0.15065870851278304\n",
      "Batch: 800, Avg. Loss: 0.1497318285703659\n",
      "Batch: 900, Avg. Loss: 0.1497175745666027\n",
      "Batch: 1000, Avg. Loss: 0.15050774708390235\n",
      "Batch: 1100, Avg. Loss: 0.15077036634087562\n",
      "Batch: 1200, Avg. Loss: 0.15110624998807906\n",
      "Batch: 1300, Avg. Loss: 0.1502155438065529\n",
      "Batch: 1400, Avg. Loss: 0.149331464022398\n",
      "Batch: 1500, Avg. Loss: 0.1495918747782707\n",
      "Batch: 1600, Avg. Loss: 0.1495403057336807\n",
      "Batch: 1700, Avg. Loss: 0.1495106676220894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1800, Avg. Loss: 0.1495738507807255\n",
      "Batch: 1900, Avg. Loss: 0.1495245161652565\n",
      "[29.44 secs] Epoch: 93/100, Training loss: 0.1498841389617144\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.14986807629466056\n",
      "Batch: 200, Avg. Loss: 0.15018128156661986\n",
      "Batch: 300, Avg. Loss: 0.15013656601309777\n",
      "Batch: 400, Avg. Loss: 0.15053633987903595\n",
      "Batch: 500, Avg. Loss: 0.150851564258337\n",
      "Batch: 600, Avg. Loss: 0.15018850311636925\n",
      "Batch: 700, Avg. Loss: 0.15053235188126565\n",
      "Batch: 800, Avg. Loss: 0.15064614340662957\n",
      "Batch: 900, Avg. Loss: 0.15008470222353934\n",
      "Batch: 1000, Avg. Loss: 0.15049154102802276\n",
      "Batch: 1100, Avg. Loss: 0.1495251965522766\n",
      "Batch: 1200, Avg. Loss: 0.14991248592734338\n",
      "Batch: 1300, Avg. Loss: 0.14962834551930426\n",
      "Batch: 1400, Avg. Loss: 0.15033922955393791\n",
      "Batch: 1500, Avg. Loss: 0.1502607937157154\n",
      "Batch: 1600, Avg. Loss: 0.14963323950767518\n",
      "Batch: 1700, Avg. Loss: 0.14947276771068574\n",
      "Batch: 1800, Avg. Loss: 0.15098178133368492\n",
      "Batch: 1900, Avg. Loss: 0.15014087289571762\n",
      "[29.387 secs] Epoch: 94/100, Training loss: 0.15016676015015634\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15041540712118148\n",
      "Batch: 200, Avg. Loss: 0.14963904827833174\n",
      "Batch: 300, Avg. Loss: 0.14977472603321076\n",
      "Batch: 400, Avg. Loss: 0.15061780259013177\n",
      "Batch: 500, Avg. Loss: 0.15009395092725752\n",
      "Batch: 600, Avg. Loss: 0.14912510946393012\n",
      "Batch: 700, Avg. Loss: 0.14939917638897895\n",
      "Batch: 800, Avg. Loss: 0.15039180994033813\n",
      "Batch: 900, Avg. Loss: 0.14939108699560166\n",
      "Batch: 1000, Avg. Loss: 0.14962654665112496\n",
      "Batch: 1100, Avg. Loss: 0.14980548039078712\n",
      "Batch: 1200, Avg. Loss: 0.15030212000012397\n",
      "Batch: 1300, Avg. Loss: 0.14945539876818656\n",
      "Batch: 1400, Avg. Loss: 0.1496671763062477\n",
      "Batch: 1500, Avg. Loss: 0.1509426899254322\n",
      "Batch: 1600, Avg. Loss: 0.15108406469225882\n",
      "Batch: 1700, Avg. Loss: 0.15016909629106523\n",
      "Batch: 1800, Avg. Loss: 0.14927057802677154\n",
      "Batch: 1900, Avg. Loss: 0.14969079449772835\n",
      "[29.355 secs] Epoch: 95/100, Training loss: 0.14992063719028095\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15003983333706855\n",
      "Batch: 200, Avg. Loss: 0.1488079822063446\n",
      "Batch: 300, Avg. Loss: 0.1495445503294468\n",
      "Batch: 400, Avg. Loss: 0.14954579532146453\n",
      "Batch: 500, Avg. Loss: 0.14995066553354264\n",
      "Batch: 600, Avg. Loss: 0.15003050044178962\n",
      "Batch: 700, Avg. Loss: 0.1494672791659832\n",
      "Batch: 800, Avg. Loss: 0.14973955899477004\n",
      "Batch: 900, Avg. Loss: 0.15082534834742545\n",
      "Batch: 1000, Avg. Loss: 0.14972552374005318\n",
      "Batch: 1100, Avg. Loss: 0.14958873346447946\n",
      "Batch: 1200, Avg. Loss: 0.1495346224308014\n",
      "Batch: 1300, Avg. Loss: 0.14976280435919762\n",
      "Batch: 1400, Avg. Loss: 0.15130624040961266\n",
      "Batch: 1500, Avg. Loss: 0.15014415249228477\n",
      "Batch: 1600, Avg. Loss: 0.14993055358529092\n",
      "Batch: 1700, Avg. Loss: 0.15012413904070854\n",
      "Batch: 1800, Avg. Loss: 0.14976856544613837\n",
      "Batch: 1900, Avg. Loss: 0.1504788701236248\n",
      "[29.37 secs] Epoch: 96/100, Training loss: 0.1499589851608418\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15095510691404343\n",
      "Batch: 200, Avg. Loss: 0.15062515795230866\n",
      "Batch: 300, Avg. Loss: 0.15007322043180465\n",
      "Batch: 400, Avg. Loss: 0.15000978112220764\n",
      "Batch: 500, Avg. Loss: 0.15008928909897803\n",
      "Batch: 600, Avg. Loss: 0.14966534659266473\n",
      "Batch: 700, Avg. Loss: 0.1507934196293354\n",
      "Batch: 800, Avg. Loss: 0.14894617035984992\n",
      "Batch: 900, Avg. Loss: 0.14991821974515915\n",
      "Batch: 1000, Avg. Loss: 0.14956654101610184\n",
      "Batch: 1100, Avg. Loss: 0.15081939682364465\n",
      "Batch: 1200, Avg. Loss: 0.1493560217320919\n",
      "Batch: 1300, Avg. Loss: 0.15069147795438767\n",
      "Batch: 1400, Avg. Loss: 0.15105778142809867\n",
      "Batch: 1500, Avg. Loss: 0.1493344284594059\n",
      "Batch: 1600, Avg. Loss: 0.1503095670044422\n",
      "Batch: 1700, Avg. Loss: 0.14907181918621062\n",
      "Batch: 1800, Avg. Loss: 0.14897414848208426\n",
      "Batch: 1900, Avg. Loss: 0.1507284866273403\n",
      "[29.402 secs] Epoch: 97/100, Training loss: 0.15008490306145092\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.14951334208250044\n",
      "Batch: 200, Avg. Loss: 0.14957833051681518\n",
      "Batch: 300, Avg. Loss: 0.1488032853603363\n",
      "Batch: 400, Avg. Loss: 0.1500801706314087\n",
      "Batch: 500, Avg. Loss: 0.1496188160777092\n",
      "Batch: 600, Avg. Loss: 0.14990033358335494\n",
      "Batch: 700, Avg. Loss: 0.1513395467400551\n",
      "Batch: 800, Avg. Loss: 0.14960110172629357\n",
      "Batch: 900, Avg. Loss: 0.15065966829657554\n",
      "Batch: 1000, Avg. Loss: 0.1507670123875141\n",
      "Batch: 1100, Avg. Loss: 0.14948657259345055\n",
      "Batch: 1200, Avg. Loss: 0.15074495494365692\n",
      "Batch: 1300, Avg. Loss: 0.15026216343045234\n",
      "Batch: 1400, Avg. Loss: 0.1490183499455452\n",
      "Batch: 1500, Avg. Loss: 0.15000927835702896\n",
      "Batch: 1600, Avg. Loss: 0.15055284947156905\n",
      "Batch: 1700, Avg. Loss: 0.14994042351841927\n",
      "Batch: 1800, Avg. Loss: 0.1497555187344551\n",
      "Batch: 1900, Avg. Loss: 0.14969767436385154\n",
      "[29.368 secs] Epoch: 98/100, Training loss: 0.14994999633657774\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.14950099989771842\n",
      "Batch: 200, Avg. Loss: 0.14958709701895714\n",
      "Batch: 300, Avg. Loss: 0.1494945378601551\n",
      "Batch: 400, Avg. Loss: 0.15078260898590087\n",
      "Batch: 500, Avg. Loss: 0.1493142181634903\n",
      "Batch: 600, Avg. Loss: 0.14995233818888665\n",
      "Batch: 700, Avg. Loss: 0.1502085429430008\n",
      "Batch: 800, Avg. Loss: 0.14960891708731652\n",
      "Batch: 900, Avg. Loss: 0.1484977798163891\n",
      "Batch: 1000, Avg. Loss: 0.15139101982116698\n",
      "Batch: 1100, Avg. Loss: 0.15076183557510375\n",
      "Batch: 1200, Avg. Loss: 0.15032816231250762\n",
      "Batch: 1300, Avg. Loss: 0.1501862244307995\n",
      "Batch: 1400, Avg. Loss: 0.14945102378726005\n",
      "Batch: 1500, Avg. Loss: 0.14916027411818505\n",
      "Batch: 1600, Avg. Loss: 0.1499308793246746\n",
      "Batch: 1700, Avg. Loss: 0.1502171576023102\n",
      "Batch: 1800, Avg. Loss: 0.14917818143963812\n",
      "Batch: 1900, Avg. Loss: 0.15061392217874528\n",
      "[29.401 secs] Epoch: 99/100, Training loss: 0.1498855734081937\n",
      "\n",
      "Batch: 100, Avg. Loss: 0.15027712807059287\n",
      "Batch: 200, Avg. Loss: 0.148914635181427\n",
      "Batch: 300, Avg. Loss: 0.14947878405451775\n",
      "Batch: 400, Avg. Loss: 0.15050318956375122\n",
      "Batch: 500, Avg. Loss: 0.1497641259431839\n",
      "Batch: 600, Avg. Loss: 0.15064383029937745\n",
      "Batch: 700, Avg. Loss: 0.1495582014322281\n",
      "Batch: 800, Avg. Loss: 0.14930628180503847\n",
      "Batch: 900, Avg. Loss: 0.14987184941768647\n",
      "Batch: 1000, Avg. Loss: 0.14965235948562622\n",
      "Batch: 1100, Avg. Loss: 0.14980577901005745\n",
      "Batch: 1200, Avg. Loss: 0.1507455027103424\n",
      "Batch: 1300, Avg. Loss: 0.14979503095149993\n",
      "Batch: 1400, Avg. Loss: 0.14937623083591461\n",
      "Batch: 1500, Avg. Loss: 0.1494554755091667\n",
      "Batch: 1600, Avg. Loss: 0.14941433534026147\n",
      "Batch: 1700, Avg. Loss: 0.14985682800412178\n",
      "Batch: 1800, Avg. Loss: 0.15046872392296792\n",
      "Batch: 1900, Avg. Loss: 0.1501135955750942\n",
      "[29.428 secs] Epoch: 100/100, Training loss: 0.1498255268456138\n",
      "\n",
      "training finished.\n",
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "train_loss = train(model, train_loader, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decreased-viking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "y": [
          0.15803474600416367,
          0.15859936130449495,
          0.15823131612861413,
          0.15799020658587482,
          0.1572895231470847,
          0.15642536499422185,
          0.15589195567668399,
          0.1565507807470515,
          0.15610802336810434,
          0.1564566586300075,
          0.15680921196693529,
          0.1564799560693416,
          0.15585025434240227,
          0.15539603420326384,
          0.15489498863688755,
          0.15471022775131701,
          0.1543834897839181,
          0.1544357205578102,
          0.15425047044286708,
          0.15441620885990293,
          0.15397470967582938,
          0.15388561636514528,
          0.15344715322021818,
          0.15348443407241252,
          0.15364062494027333,
          0.153859162342829,
          0.15350701981734108,
          0.15352314584788426,
          0.15382142229998977,
          0.15466241475991607,
          0.15509815765744955,
          0.15524998284350153,
          0.15483010779139694,
          0.15525739805481206,
          0.15487921246334133,
          0.153775638367832,
          0.1537902228069037,
          0.15421183836649238,
          0.1548009702712755,
          0.15409599027254198,
          0.15366953599172337,
          0.15309004963755973,
          0.15253920840173807,
          0.1527633959906006,
          0.15220187919380232,
          0.1517336209406628,
          0.1516592390873415,
          0.15189395443047327,
          0.15173413630426236,
          0.15134478199506368,
          0.15154932027524423,
          0.15116066005969364,
          0.15103872494053328,
          0.1510106646126954,
          0.1511050293654844,
          0.1512160452279122,
          0.15070164973867586,
          0.15092905357617317,
          0.15108484605531244,
          0.15159018614549596,
          0.15129276068391184,
          0.15138471189852015,
          0.15100698861671935,
          0.1512644381520692,
          0.15115159383175195,
          0.1513241687398728,
          0.15169502501905024,
          0.15155254553015912,
          0.1516259305842579,
          0.15156098146338545,
          0.15178654664706062,
          0.15213102819121604,
          0.15168740313610743,
          0.15117868774226403,
          0.15134832573370166,
          0.15089904548964456,
          0.15110667455586832,
          0.15055709907226456,
          0.15056187651113453,
          0.15020565599386132,
          0.15020082261081605,
          0.14996045626539778,
          0.1499481036908307,
          0.15068379459385983,
          0.15028581076598094,
          0.15023089401584078,
          0.15079415970869903,
          0.15102915898224714,
          0.15117252065953604,
          0.15072730261386355,
          0.15045646285235942,
          0.1500554367091541,
          0.1498841389617144,
          0.15016676015015634,
          0.14992063719028095,
          0.1499589851608418,
          0.15008490306145092,
          0.14994999633657774,
          0.1498855734081937,
          0.1498255268456138
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"fc22d104-c194-4332-b5ca-cad1abbc20fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fc22d104-c194-4332-b5ca-cad1abbc20fe\")) {                    Plotly.newPlot(                        \"fc22d104-c194-4332-b5ca-cad1abbc20fe\",                        [{\"mode\": \"lines+markers\", \"type\": \"scatter\", \"y\": [0.15803474600416367, 0.15859936130449495, 0.15823131612861413, 0.15799020658587482, 0.1572895231470847, 0.15642536499422185, 0.15589195567668399, 0.1565507807470515, 0.15610802336810434, 0.1564566586300075, 0.15680921196693529, 0.1564799560693416, 0.15585025434240227, 0.15539603420326384, 0.15489498863688755, 0.15471022775131701, 0.1543834897839181, 0.1544357205578102, 0.15425047044286708, 0.15441620885990293, 0.15397470967582938, 0.15388561636514528, 0.15344715322021818, 0.15348443407241252, 0.15364062494027333, 0.153859162342829, 0.15350701981734108, 0.15352314584788426, 0.15382142229998977, 0.15466241475991607, 0.15509815765744955, 0.15524998284350153, 0.15483010779139694, 0.15525739805481206, 0.15487921246334133, 0.153775638367832, 0.1537902228069037, 0.15421183836649238, 0.1548009702712755, 0.15409599027254198, 0.15366953599172337, 0.15309004963755973, 0.15253920840173807, 0.1527633959906006, 0.15220187919380232, 0.1517336209406628, 0.1516592390873415, 0.15189395443047327, 0.15173413630426236, 0.15134478199506368, 0.15154932027524423, 0.15116066005969364, 0.15103872494053328, 0.1510106646126954, 0.1511050293654844, 0.1512160452279122, 0.15070164973867586, 0.15092905357617317, 0.15108484605531244, 0.15159018614549596, 0.15129276068391184, 0.15138471189852015, 0.15100698861671935, 0.1512644381520692, 0.15115159383175195, 0.1513241687398728, 0.15169502501905024, 0.15155254553015912, 0.1516259305842579, 0.15156098146338545, 0.15178654664706062, 0.15213102819121604, 0.15168740313610743, 0.15117868774226403, 0.15134832573370166, 0.15089904548964456, 0.15110667455586832, 0.15055709907226456, 0.15056187651113453, 0.15020565599386132, 0.15020082261081605, 0.14996045626539778, 0.1499481036908307, 0.15068379459385983, 0.15028581076598094, 0.15023089401584078, 0.15079415970869903, 0.15102915898224714, 0.15117252065953604, 0.15072730261386355, 0.15045646285235942, 0.1500554367091541, 0.1498841389617144, 0.15016676015015634, 0.14992063719028095, 0.1499589851608418, 0.15008490306145092, 0.14994999633657774, 0.1498855734081937, 0.1498255268456138]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fc22d104-c194-4332-b5ca-cad1abbc20fe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure(data=go.Scatter(y=train_loss, mode='lines+markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-selling",
   "metadata": {},
   "source": [
    "## Loading existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "external-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "model_path = '.\\\\models\\\\model_20210604204023.pt'\n",
    "\n",
    "model, optimizer, epoch, train_loss = load_model(model_path, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spoken-james",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "y": [
          0.07325822114944458,
          0.046621911227703094,
          0.06720030307769775,
          0.16485078632831573,
          0.12710250914096832,
          0.1459663063287735,
          0.12971051037311554,
          0.15653082728385925,
          0.198111891746521,
          0.14898745715618134,
          0.12907369434833527,
          0.111030712723732,
          0.16316737234592438,
          0.1617959886789322,
          0.33506932854652405,
          0.12696446478366852,
          0.1364874690771103,
          0.08606074750423431,
          0.12954524159431458,
          0.1432657092809677,
          0.1136399582028389,
          0.08200328797101974,
          0.1454918384552002,
          0.28644445538520813,
          0.16073265671730042,
          0.21583983302116394,
          0.16945916414260864,
          0.15576297044754028,
          0.19964860379695892,
          0.17339342832565308,
          0.15896739065647125,
          0.2291772961616516,
          0.13206467032432556,
          0.0874718576669693,
          0.17257830500602722,
          0.18777193129062653,
          0.1639670431613922,
          0.18476340174674988,
          0.1783599853515625,
          0.1860644370317459,
          0.19901567697525024,
          0.16934537887573242,
          0.16442176699638367,
          0.23325344920158386,
          0.2958710193634033,
          0.1746826171875,
          0.18182051181793213,
          0.13633711636066437,
          0.1519816517829895,
          0.09520389884710312,
          0.07652873545885086,
          0.10306933522224426,
          0.13169322907924652,
          0.10816458612680435,
          0.15766511857509613,
          0.2055993229150772,
          0.09458046406507492,
          0.10191605985164642,
          0.15882836282253265,
          0.11121822148561478,
          0.10922331362962723,
          0.1432362049818039,
          0.12006987631320953,
          0.14046095311641693,
          0.25387635827064514,
          0.3032378852367401,
          0.2795812785625458,
          0.1375778466463089,
          0.09841946512460709,
          0.11977776885032654,
          0.09747014194726944,
          0.0929965078830719,
          0.13228589296340942,
          0.18146248161792755,
          0.07501769065856934,
          0.1163451075553894,
          0.07335890829563141,
          0.07902486622333527,
          0.13600625097751617,
          0.1289171278476715,
          0.10956058651208878,
          0.11032567173242569,
          0.14681468904018402,
          0.11299274861812592,
          0.22152002155780792,
          0.1919240653514862,
          0.06246092543005943,
          0.1328292191028595,
          0.11101694405078888,
          0.10238230973482132,
          0.16905175149440765,
          0.11841849982738495,
          0.18636929988861084,
          0.18265648186206818,
          0.0944896712899208,
          0.13677646219730377,
          0.1434733122587204,
          0.1353217363357544,
          0.0949816033244133,
          0.16912637650966644,
          0.09781717509031296,
          0.1255466192960739,
          0.09371770918369293,
          0.08950789272785187,
          0.07410746067762375,
          0.07255200296640396,
          0.2165280431509018,
          0.153487890958786,
          0.06905029714107513,
          0.09821484982967377,
          0.0975281372666359,
          0.20161662995815277,
          0.09833288192749023,
          0.0784778818488121,
          0.13297110795974731,
          0.1730143129825592,
          0.12193738669157028,
          0.10848813503980637,
          0.171949103474617,
          0.1431094855070114,
          0.1032666265964508,
          0.16162648797035217,
          0.10991093516349792,
          0.15464182198047638,
          0.140188530087471,
          0.17085909843444824,
          0.12849554419517517,
          0.10204945504665375,
          0.14654800295829773,
          0.09545478969812393,
          0.09279089421033859,
          0.07417565584182739,
          0.2240176796913147,
          0.07833343744277954,
          0.15677063167095184,
          0.15273869037628174,
          0.11962566524744034,
          0.12586133182048798,
          0.1610664576292038,
          0.1266411542892456,
          0.1612759381532669,
          0.20347146689891815,
          0.11778496205806732,
          0.15298163890838623,
          0.17994144558906555,
          0.18240343034267426,
          0.14632634818553925,
          0.10512799769639969,
          0.0937681570649147,
          0.06736508756875992,
          0.1234297901391983,
          0.09154679626226425,
          0.11299758404493332,
          0.13459570705890656,
          0.0479501336812973,
          0.06714044511318207,
          0.08884380757808685,
          0.11738302558660507,
          0.1712781935930252,
          0.21430465579032898,
          0.1918240189552307,
          0.24107995629310608,
          0.2525804340839386,
          0.22905899584293365,
          0.11874958872795105,
          0.11202894896268845,
          0.13168995082378387,
          0.1595546007156372,
          0.10862462967634201,
          0.07191995531320572,
          0.22224761545658112,
          0.12799577414989471,
          0.23530934751033783,
          0.18200302124023438,
          0.3228641152381897,
          0.20183773338794708,
          0.11548221856355667,
          0.09182249754667282,
          0.09607294946908951,
          0.14899864792823792,
          0.11937244236469269,
          0.07235181331634521,
          0.1423594206571579,
          0.16424812376499176,
          0.19059692323207855,
          0.14286509156227112,
          0.12823978066444397,
          0.1376001238822937,
          0.17131197452545166,
          0.18927983939647675,
          0.13881465792655945,
          0.10128127038478851,
          0.16890005767345428,
          0.23599225282669067,
          0.1507006287574768,
          0.14053720235824585,
          0.1896124631166458,
          0.13757319748401642,
          0.1302649974822998,
          0.12084824591875076,
          0.16191519796848297,
          0.14788351953029633,
          0.1892034113407135,
          0.12923382222652435,
          0.10898352414369583,
          0.11161235719919205,
          0.08811800926923752,
          0.07601764053106308,
          0.06075778231024742,
          0.10608600080013275,
          0.0947401225566864,
          0.16163301467895508,
          0.1133798137307167,
          0.11718247085809708,
          0.18535299599170685,
          0.13435688614845276,
          0.15966859459877014,
          0.12972719967365265,
          0.08108724653720856,
          0.10074938833713531,
          0.1406164914369583,
          0.1265261024236679,
          0.21911904215812683,
          0.1612398475408554,
          0.17169809341430664,
          0.1876171976327896,
          0.09710627049207687,
          0.13097473978996277,
          0.11136196553707123,
          0.11179593950510025,
          0.12640899419784546,
          0.14167062938213348,
          0.08488958328962326,
          0.061738818883895874,
          0.061115507036447525,
          0.08735518902540207,
          0.1009601280093193,
          0.1483961045742035,
          0.20026050508022308,
          0.16275683045387268,
          0.13506177067756653,
          0.12759366631507874,
          0.13098476827144623,
          0.11728356033563614,
          0.19801796972751617,
          0.11673909425735474,
          0.1791618913412094,
          0.14421477913856506,
          0.13740511238574982,
          0.11383973807096481,
          0.19402222335338593,
          0.1530493050813675,
          0.17849715054035187,
          0.17521074414253235,
          0.20712552964687347,
          0.15135329961776733,
          0.09523819386959076,
          0.12115438282489777,
          0.07935153692960739,
          0.12350451201200485,
          0.14362847805023193,
          0.12632429599761963,
          0.08486419171094894,
          0.10593845695257187,
          0.12106519192457199,
          0.12890535593032837,
          0.12392686307430267,
          0.14798717200756073,
          0.20607176423072815,
          0.27902737259864807,
          0.1261579841375351,
          0.12056336551904678,
          0.12047158926725388,
          0.10367570072412491,
          0.16205300390720367,
          0.13293126225471497,
          0.11716917157173157,
          0.09706118702888489,
          0.11126483976840973,
          0.08598751574754715,
          0.1037014052271843,
          0.11354821920394897,
          0.1338435858488083,
          0.12743361294269562,
          0.10786085575819016,
          0.10215684771537781,
          0.09350883215665817,
          0.11798455566167831,
          0.1431598961353302,
          0.1387968808412552,
          0.09417043626308441,
          0.14715127646923065,
          0.12457455694675446,
          0.13882724940776825,
          0.10544068366289139,
          0.12394703179597855,
          0.17544519901275635,
          0.13132837414741516,
          0.08603368699550629,
          0.1467699259519577,
          0.20112453401088715,
          0.24517163634300232,
          0.11410683393478394,
          0.1067178025841713,
          0.12830451130867004,
          0.15349702537059784,
          0.13893364369869232,
          0.21687574684619904,
          0.2698846757411957,
          0.11755113303661346,
          0.165391743183136,
          0.1677243709564209,
          0.18298296630382538,
          0.075160913169384,
          0.16049057245254517,
          0.12629537284374237,
          0.14959117770195007,
          0.1862926185131073,
          0.12142036110162735,
          0.10293084383010864,
          0.12411624938249588,
          0.10221125930547714,
          0.11601273715496063,
          0.17071837186813354,
          0.09029902517795563,
          0.13326822221279144,
          0.06898127496242523,
          0.15339632332324982,
          0.17631013691425323,
          0.11266165971755981,
          0.23991312086582184,
          0.2770238220691681,
          0.1493844985961914,
          0.06988237798213959,
          0.07315784692764282,
          0.17843806743621826,
          0.1359601467847824,
          0.20143014192581177,
          0.12238198518753052,
          0.05462123081088066,
          0.09342905879020691,
          0.10187128931283951,
          0.09269065409898758,
          0.10431944578886032,
          0.12120895832777023,
          0.1734059900045395,
          0.1710258573293686,
          0.13269421458244324,
          0.11644919216632843,
          0.10370781272649765,
          0.10221373289823532,
          0.10552633553743362,
          0.1723296195268631,
          0.1841452568769455,
          0.19496816396713257,
          0.16819722950458527,
          0.16799603402614594,
          0.07412406802177429,
          0.09505954384803772,
          0.10533912479877472,
          0.10944083333015442,
          0.14110784232616425,
          0.12964138388633728,
          0.1346270740032196,
          0.08505754917860031,
          0.20852108299732208,
          0.29625260829925537,
          0.15289407968521118,
          0.16959300637245178,
          0.13401180505752563,
          0.1823410540819168,
          0.11055412888526917,
          0.09680241346359253,
          0.05433385446667671,
          0.15508241951465607,
          0.14146676659584045,
          0.16040490567684174,
          0.10136761516332626,
          0.13790644705295563,
          0.2445770502090454,
          0.1571437418460846,
          0.09856881201267242,
          0.13217195868492126,
          0.09865263849496841,
          0.10926969349384308,
          0.10894528031349182,
          0.22703516483306885,
          0.20033946633338928,
          0.10985731333494186,
          0.0641864612698555,
          0.15891985595226288,
          0.11871176958084106,
          0.141975536942482,
          0.06335268914699554,
          0.13221074640750885,
          0.060082338750362396,
          0.13654518127441406,
          0.14391298592090607,
          0.10519199818372726,
          0.1631087064743042,
          0.20526905357837677,
          0.17462241649627686,
          0.11712919175624847,
          0.20340676605701447,
          0.16285471618175507,
          0.12237237393856049,
          0.2071896344423294,
          0.1326366662979126,
          0.09815986454486847,
          0.13110873103141785,
          0.16516755521297455,
          0.1472521871328354,
          0.1583743542432785,
          0.19895677268505096,
          0.18443121016025543,
          0.1595292091369629,
          0.12381649762392044,
          0.11444039642810822,
          0.1399105042219162,
          0.10430007427930832,
          0.1203296035528183,
          0.09778721630573273,
          0.19060659408569336,
          0.16167116165161133,
          0.1796778440475464,
          0.13418711721897125,
          0.21282775700092316,
          0.1277492791414261,
          0.13439655303955078,
          0.17603141069412231,
          0.0692906379699707,
          0.06861850619316101,
          0.07497812807559967,
          0.06161465495824814,
          0.11165235191583633,
          0.10334337502717972,
          0.09130892902612686,
          0.13044527173042297,
          0.2484094202518463,
          0.15436916053295135,
          0.13923828303813934,
          0.1316392719745636,
          0.24168464541435242,
          0.11387742310762405,
          0.12968817353248596,
          0.1618202030658722,
          0.1150609478354454,
          0.08593174815177917,
          0.1658071130514145,
          0.14190731942653656,
          0.09070904552936554,
          0.10360539704561234,
          0.14580146968364716,
          0.07669194042682648,
          0.09917616844177246,
          0.19912126660346985,
          0.17818692326545715,
          0.08700697869062424,
          0.073041632771492,
          0.19919425249099731,
          0.21664252877235413,
          0.1799723207950592,
          0.1621520072221756,
          0.10909339785575867,
          0.14950770139694214,
          0.11765126883983612,
          0.12231653183698654,
          0.2123502492904663,
          0.09501281380653381,
          0.0954187661409378,
          0.1278829276561737,
          0.11723067611455917,
          0.18068662285804749,
          0.27953970432281494,
          0.1327679455280304,
          0.1122889444231987,
          0.11272739619016647,
          0.11999497562646866,
          0.1217028796672821,
          0.11823742091655731,
          0.12147535383701324,
          0.11782743036746979,
          0.13321222364902496,
          0.14750121533870697,
          0.17149388790130615,
          0.11737289279699326,
          0.08358392864465714,
          0.08706406503915787,
          0.11823789775371552,
          0.14089691638946533,
          0.20425353944301605,
          0.09849721193313599,
          0.21346808969974518,
          0.1646120399236679,
          0.20859473943710327,
          0.10133227705955505,
          0.1009286567568779,
          0.11871008574962616,
          0.1708393543958664,
          0.13237333297729492
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"441076da-431f-4c4e-860c-01d6ce5dd745\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"441076da-431f-4c4e-860c-01d6ce5dd745\")) {                    Plotly.newPlot(                        \"441076da-431f-4c4e-860c-01d6ce5dd745\",                        [{\"mode\": \"lines+markers\", \"type\": \"scatter\", \"y\": [0.07325822114944458, 0.046621911227703094, 0.06720030307769775, 0.16485078632831573, 0.12710250914096832, 0.1459663063287735, 0.12971051037311554, 0.15653082728385925, 0.198111891746521, 0.14898745715618134, 0.12907369434833527, 0.111030712723732, 0.16316737234592438, 0.1617959886789322, 0.33506932854652405, 0.12696446478366852, 0.1364874690771103, 0.08606074750423431, 0.12954524159431458, 0.1432657092809677, 0.1136399582028389, 0.08200328797101974, 0.1454918384552002, 0.28644445538520813, 0.16073265671730042, 0.21583983302116394, 0.16945916414260864, 0.15576297044754028, 0.19964860379695892, 0.17339342832565308, 0.15896739065647125, 0.2291772961616516, 0.13206467032432556, 0.0874718576669693, 0.17257830500602722, 0.18777193129062653, 0.1639670431613922, 0.18476340174674988, 0.1783599853515625, 0.1860644370317459, 0.19901567697525024, 0.16934537887573242, 0.16442176699638367, 0.23325344920158386, 0.2958710193634033, 0.1746826171875, 0.18182051181793213, 0.13633711636066437, 0.1519816517829895, 0.09520389884710312, 0.07652873545885086, 0.10306933522224426, 0.13169322907924652, 0.10816458612680435, 0.15766511857509613, 0.2055993229150772, 0.09458046406507492, 0.10191605985164642, 0.15882836282253265, 0.11121822148561478, 0.10922331362962723, 0.1432362049818039, 0.12006987631320953, 0.14046095311641693, 0.25387635827064514, 0.3032378852367401, 0.2795812785625458, 0.1375778466463089, 0.09841946512460709, 0.11977776885032654, 0.09747014194726944, 0.0929965078830719, 0.13228589296340942, 0.18146248161792755, 0.07501769065856934, 0.1163451075553894, 0.07335890829563141, 0.07902486622333527, 0.13600625097751617, 0.1289171278476715, 0.10956058651208878, 0.11032567173242569, 0.14681468904018402, 0.11299274861812592, 0.22152002155780792, 0.1919240653514862, 0.06246092543005943, 0.1328292191028595, 0.11101694405078888, 0.10238230973482132, 0.16905175149440765, 0.11841849982738495, 0.18636929988861084, 0.18265648186206818, 0.0944896712899208, 0.13677646219730377, 0.1434733122587204, 0.1353217363357544, 0.0949816033244133, 0.16912637650966644, 0.09781717509031296, 0.1255466192960739, 0.09371770918369293, 0.08950789272785187, 0.07410746067762375, 0.07255200296640396, 0.2165280431509018, 0.153487890958786, 0.06905029714107513, 0.09821484982967377, 0.0975281372666359, 0.20161662995815277, 0.09833288192749023, 0.0784778818488121, 0.13297110795974731, 0.1730143129825592, 0.12193738669157028, 0.10848813503980637, 0.171949103474617, 0.1431094855070114, 0.1032666265964508, 0.16162648797035217, 0.10991093516349792, 0.15464182198047638, 0.140188530087471, 0.17085909843444824, 0.12849554419517517, 0.10204945504665375, 0.14654800295829773, 0.09545478969812393, 0.09279089421033859, 0.07417565584182739, 0.2240176796913147, 0.07833343744277954, 0.15677063167095184, 0.15273869037628174, 0.11962566524744034, 0.12586133182048798, 0.1610664576292038, 0.1266411542892456, 0.1612759381532669, 0.20347146689891815, 0.11778496205806732, 0.15298163890838623, 0.17994144558906555, 0.18240343034267426, 0.14632634818553925, 0.10512799769639969, 0.0937681570649147, 0.06736508756875992, 0.1234297901391983, 0.09154679626226425, 0.11299758404493332, 0.13459570705890656, 0.0479501336812973, 0.06714044511318207, 0.08884380757808685, 0.11738302558660507, 0.1712781935930252, 0.21430465579032898, 0.1918240189552307, 0.24107995629310608, 0.2525804340839386, 0.22905899584293365, 0.11874958872795105, 0.11202894896268845, 0.13168995082378387, 0.1595546007156372, 0.10862462967634201, 0.07191995531320572, 0.22224761545658112, 0.12799577414989471, 0.23530934751033783, 0.18200302124023438, 0.3228641152381897, 0.20183773338794708, 0.11548221856355667, 0.09182249754667282, 0.09607294946908951, 0.14899864792823792, 0.11937244236469269, 0.07235181331634521, 0.1423594206571579, 0.16424812376499176, 0.19059692323207855, 0.14286509156227112, 0.12823978066444397, 0.1376001238822937, 0.17131197452545166, 0.18927983939647675, 0.13881465792655945, 0.10128127038478851, 0.16890005767345428, 0.23599225282669067, 0.1507006287574768, 0.14053720235824585, 0.1896124631166458, 0.13757319748401642, 0.1302649974822998, 0.12084824591875076, 0.16191519796848297, 0.14788351953029633, 0.1892034113407135, 0.12923382222652435, 0.10898352414369583, 0.11161235719919205, 0.08811800926923752, 0.07601764053106308, 0.06075778231024742, 0.10608600080013275, 0.0947401225566864, 0.16163301467895508, 0.1133798137307167, 0.11718247085809708, 0.18535299599170685, 0.13435688614845276, 0.15966859459877014, 0.12972719967365265, 0.08108724653720856, 0.10074938833713531, 0.1406164914369583, 0.1265261024236679, 0.21911904215812683, 0.1612398475408554, 0.17169809341430664, 0.1876171976327896, 0.09710627049207687, 0.13097473978996277, 0.11136196553707123, 0.11179593950510025, 0.12640899419784546, 0.14167062938213348, 0.08488958328962326, 0.061738818883895874, 0.061115507036447525, 0.08735518902540207, 0.1009601280093193, 0.1483961045742035, 0.20026050508022308, 0.16275683045387268, 0.13506177067756653, 0.12759366631507874, 0.13098476827144623, 0.11728356033563614, 0.19801796972751617, 0.11673909425735474, 0.1791618913412094, 0.14421477913856506, 0.13740511238574982, 0.11383973807096481, 0.19402222335338593, 0.1530493050813675, 0.17849715054035187, 0.17521074414253235, 0.20712552964687347, 0.15135329961776733, 0.09523819386959076, 0.12115438282489777, 0.07935153692960739, 0.12350451201200485, 0.14362847805023193, 0.12632429599761963, 0.08486419171094894, 0.10593845695257187, 0.12106519192457199, 0.12890535593032837, 0.12392686307430267, 0.14798717200756073, 0.20607176423072815, 0.27902737259864807, 0.1261579841375351, 0.12056336551904678, 0.12047158926725388, 0.10367570072412491, 0.16205300390720367, 0.13293126225471497, 0.11716917157173157, 0.09706118702888489, 0.11126483976840973, 0.08598751574754715, 0.1037014052271843, 0.11354821920394897, 0.1338435858488083, 0.12743361294269562, 0.10786085575819016, 0.10215684771537781, 0.09350883215665817, 0.11798455566167831, 0.1431598961353302, 0.1387968808412552, 0.09417043626308441, 0.14715127646923065, 0.12457455694675446, 0.13882724940776825, 0.10544068366289139, 0.12394703179597855, 0.17544519901275635, 0.13132837414741516, 0.08603368699550629, 0.1467699259519577, 0.20112453401088715, 0.24517163634300232, 0.11410683393478394, 0.1067178025841713, 0.12830451130867004, 0.15349702537059784, 0.13893364369869232, 0.21687574684619904, 0.2698846757411957, 0.11755113303661346, 0.165391743183136, 0.1677243709564209, 0.18298296630382538, 0.075160913169384, 0.16049057245254517, 0.12629537284374237, 0.14959117770195007, 0.1862926185131073, 0.12142036110162735, 0.10293084383010864, 0.12411624938249588, 0.10221125930547714, 0.11601273715496063, 0.17071837186813354, 0.09029902517795563, 0.13326822221279144, 0.06898127496242523, 0.15339632332324982, 0.17631013691425323, 0.11266165971755981, 0.23991312086582184, 0.2770238220691681, 0.1493844985961914, 0.06988237798213959, 0.07315784692764282, 0.17843806743621826, 0.1359601467847824, 0.20143014192581177, 0.12238198518753052, 0.05462123081088066, 0.09342905879020691, 0.10187128931283951, 0.09269065409898758, 0.10431944578886032, 0.12120895832777023, 0.1734059900045395, 0.1710258573293686, 0.13269421458244324, 0.11644919216632843, 0.10370781272649765, 0.10221373289823532, 0.10552633553743362, 0.1723296195268631, 0.1841452568769455, 0.19496816396713257, 0.16819722950458527, 0.16799603402614594, 0.07412406802177429, 0.09505954384803772, 0.10533912479877472, 0.10944083333015442, 0.14110784232616425, 0.12964138388633728, 0.1346270740032196, 0.08505754917860031, 0.20852108299732208, 0.29625260829925537, 0.15289407968521118, 0.16959300637245178, 0.13401180505752563, 0.1823410540819168, 0.11055412888526917, 0.09680241346359253, 0.05433385446667671, 0.15508241951465607, 0.14146676659584045, 0.16040490567684174, 0.10136761516332626, 0.13790644705295563, 0.2445770502090454, 0.1571437418460846, 0.09856881201267242, 0.13217195868492126, 0.09865263849496841, 0.10926969349384308, 0.10894528031349182, 0.22703516483306885, 0.20033946633338928, 0.10985731333494186, 0.0641864612698555, 0.15891985595226288, 0.11871176958084106, 0.141975536942482, 0.06335268914699554, 0.13221074640750885, 0.060082338750362396, 0.13654518127441406, 0.14391298592090607, 0.10519199818372726, 0.1631087064743042, 0.20526905357837677, 0.17462241649627686, 0.11712919175624847, 0.20340676605701447, 0.16285471618175507, 0.12237237393856049, 0.2071896344423294, 0.1326366662979126, 0.09815986454486847, 0.13110873103141785, 0.16516755521297455, 0.1472521871328354, 0.1583743542432785, 0.19895677268505096, 0.18443121016025543, 0.1595292091369629, 0.12381649762392044, 0.11444039642810822, 0.1399105042219162, 0.10430007427930832, 0.1203296035528183, 0.09778721630573273, 0.19060659408569336, 0.16167116165161133, 0.1796778440475464, 0.13418711721897125, 0.21282775700092316, 0.1277492791414261, 0.13439655303955078, 0.17603141069412231, 0.0692906379699707, 0.06861850619316101, 0.07497812807559967, 0.06161465495824814, 0.11165235191583633, 0.10334337502717972, 0.09130892902612686, 0.13044527173042297, 0.2484094202518463, 0.15436916053295135, 0.13923828303813934, 0.1316392719745636, 0.24168464541435242, 0.11387742310762405, 0.12968817353248596, 0.1618202030658722, 0.1150609478354454, 0.08593174815177917, 0.1658071130514145, 0.14190731942653656, 0.09070904552936554, 0.10360539704561234, 0.14580146968364716, 0.07669194042682648, 0.09917616844177246, 0.19912126660346985, 0.17818692326545715, 0.08700697869062424, 0.073041632771492, 0.19919425249099731, 0.21664252877235413, 0.1799723207950592, 0.1621520072221756, 0.10909339785575867, 0.14950770139694214, 0.11765126883983612, 0.12231653183698654, 0.2123502492904663, 0.09501281380653381, 0.0954187661409378, 0.1278829276561737, 0.11723067611455917, 0.18068662285804749, 0.27953970432281494, 0.1327679455280304, 0.1122889444231987, 0.11272739619016647, 0.11999497562646866, 0.1217028796672821, 0.11823742091655731, 0.12147535383701324, 0.11782743036746979, 0.13321222364902496, 0.14750121533870697, 0.17149388790130615, 0.11737289279699326, 0.08358392864465714, 0.08706406503915787, 0.11823789775371552, 0.14089691638946533, 0.20425353944301605, 0.09849721193313599, 0.21346808969974518, 0.1646120399236679, 0.20859473943710327, 0.10133227705955505, 0.1009286567568779, 0.11871008574962616, 0.1708393543958664, 0.13237333297729492]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('441076da-431f-4c4e-860c-01d6ce5dd745');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset(path='.\\\\data\\\\training.h5', key='normal', simulation=1)\n",
    "mse = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for data in train_dataset:\n",
    "    X = data['X'].to(device)\n",
    "    output = model(X)\n",
    "    mse.append(criterion(output, X).item())\n",
    "    \n",
    "fig = go.Figure(data=go.Scatter(y=mse, mode='lines+markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "multiple-congress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "y": [
          0.07325822114944458,
          0.046621911227703094,
          0.06720030307769775,
          0.16485078632831573,
          0.12710250914096832,
          0.1459663063287735,
          0.12971051037311554,
          0.15653082728385925,
          0.198111891746521,
          0.14898745715618134,
          0.12907369434833527,
          0.111030712723732,
          0.16316737234592438,
          0.1617959886789322,
          0.33506932854652405,
          0.12696446478366852,
          0.1364874690771103,
          0.08606074750423431,
          0.12954524159431458,
          0.1432657092809677,
          0.0923694521188736,
          0.1616511046886444,
          0.21592757105827332,
          0.3944830894470215,
          0.5662891864776611,
          0.8975823521614075,
          0.6645099520683289,
          0.9026135206222534,
          1.3380711078643799,
          1.61506986618042,
          2.1740567684173584,
          2.5584652423858643,
          3.191880941390991,
          3.4603757858276367,
          3.9641401767730713,
          4.193936824798584,
          4.879309177398682,
          5.407907009124756,
          5.670400619506836,
          5.927031993865967,
          6.847367763519287,
          7.207455158233643,
          8.286916732788086,
          8.62362003326416,
          8.873421669006348,
          7.410782337188721,
          10.065760612487793,
          8.366803169250488,
          9.379404067993164,
          8.752954483032227,
          9.280055046081543,
          9.739532470703125,
          11.695544242858887,
          11.016702651977539,
          10.900053977966309,
          12.411018371582031,
          11.351550102233887,
          11.979973793029785,
          11.608773231506348,
          10.273354530334473,
          10.966498374938965,
          11.530841827392578,
          12.82982063293457,
          12.024937629699707,
          13.665803909301758,
          13.68529224395752,
          14.097813606262207,
          14.870441436767578,
          15.125972747802734,
          14.886341094970703,
          13.729607582092285,
          13.267682075500488,
          12.934028625488281,
          13.424786567687988,
          12.998279571533203,
          13.198681831359863,
          13.366549491882324,
          14.31176471710205,
          13.942516326904297,
          13.679277420043945,
          14.730884552001953,
          14.938858985900879,
          11.421335220336914,
          12.473701477050781,
          13.745439529418945,
          13.37606430053711,
          12.3412446975708,
          11.926034927368164,
          14.440260887145996,
          13.307440757751465,
          11.517152786254883,
          10.369356155395508,
          11.751615524291992,
          11.568998336791992,
          12.284360885620117,
          11.970221519470215,
          11.543891906738281,
          10.261797904968262,
          10.031187057495117,
          10.475564002990723,
          10.450770378112793,
          9.316959381103516,
          8.816927909851074,
          8.786959648132324,
          9.022683143615723,
          8.910444259643555,
          8.356245994567871,
          8.667119979858398,
          7.9119954109191895,
          7.4927263259887695,
          7.663361072540283,
          7.793565273284912,
          6.954769611358643,
          6.4790263175964355,
          8.73556137084961,
          8.314706802368164,
          8.168072700500488,
          7.897907733917236,
          7.395549297332764,
          7.985322952270508,
          7.10295295715332,
          7.187770366668701,
          8.743927001953125,
          9.1899995803833,
          9.105757713317871,
          9.975050926208496,
          9.63197135925293,
          9.907820701599121,
          8.85027027130127,
          8.559206008911133,
          8.57529067993164,
          8.833267211914062,
          8.729986190795898,
          8.857508659362793,
          8.39091682434082,
          8.206887245178223,
          9.3495512008667,
          8.955519676208496,
          9.104303359985352,
          9.284830093383789,
          9.826787948608398,
          9.682920455932617,
          9.878460884094238,
          8.509788513183594,
          8.631022453308105,
          8.21363639831543,
          9.33701229095459,
          8.45040225982666,
          9.089249610900879,
          8.268509864807129,
          7.5947184562683105,
          6.929995059967041,
          6.507326602935791,
          6.862899303436279,
          7.599410533905029,
          7.450240612030029,
          7.928675651550293,
          8.027159690856934,
          7.326937198638916,
          8.095606803894043,
          7.398421764373779,
          6.357515811920166,
          8.641571044921875,
          9.217506408691406,
          6.89894962310791,
          5.703174114227295,
          5.5876946449279785,
          5.923852443695068,
          6.276574611663818,
          6.363499641418457,
          7.113084316253662,
          6.741958141326904,
          7.518833160400391,
          6.688551425933838,
          6.661281108856201,
          6.14520263671875,
          5.610434532165527,
          5.923949241638184,
          7.198859214782715,
          7.119760513305664,
          6.75717306137085,
          6.337278366088867,
          6.2851104736328125,
          6.263066291809082,
          6.4748125076293945,
          5.894382476806641,
          5.84127140045166,
          5.621703147888184,
          5.437796592712402,
          5.185561656951904,
          5.692211627960205,
          5.596507549285889,
          6.151829719543457,
          6.414225101470947,
          5.537108421325684,
          5.586088180541992,
          6.750873565673828,
          6.31066370010376,
          5.3838791847229,
          5.630784034729004,
          5.298333168029785,
          5.177587985992432,
          5.469091892242432,
          5.686617374420166,
          5.053889751434326,
          5.904087066650391,
          5.684298992156982,
          5.69293212890625,
          5.140252113342285,
          5.4160614013671875,
          4.517979621887207,
          4.734652996063232,
          5.522044658660889,
          5.715340614318848,
          5.566802024841309,
          5.618587017059326,
          5.9890055656433105,
          6.741981029510498,
          5.762358665466309,
          5.73344087600708,
          6.240195274353027,
          5.801384925842285,
          4.79604959487915,
          5.1581621170043945,
          6.036635875701904,
          5.406981468200684,
          5.487913131713867,
          5.047749996185303,
          5.061098575592041,
          5.308687210083008,
          5.00323486328125,
          4.865390300750732,
          4.516645431518555,
          4.245776653289795,
          4.780021667480469,
          4.518180847167969,
          4.5894455909729,
          4.550908088684082,
          4.43669319152832,
          4.401508331298828,
          4.565305233001709,
          5.0450053215026855,
          4.57665491104126,
          4.745485305786133,
          5.940205097198486,
          4.911580562591553,
          4.733391761779785,
          4.687233924865723,
          4.810449600219727,
          4.802178382873535,
          5.698487758636475,
          5.903448581695557,
          4.534120082855225,
          4.89021635055542,
          4.866110324859619,
          5.46573543548584,
          5.2376909255981445,
          5.548262596130371,
          5.274167537689209,
          4.354578495025635,
          4.220457077026367,
          3.7868494987487793,
          5.395148754119873,
          4.937014102935791,
          4.9019389152526855,
          5.744762897491455,
          3.7664296627044678,
          3.8691887855529785,
          4.72027587890625,
          4.18048620223999,
          4.2144904136657715,
          4.09060001373291,
          4.7158660888671875,
          4.383787631988525,
          4.225195407867432,
          4.083127498626709,
          5.062377452850342,
          3.9988927841186523,
          6.04597282409668,
          6.262594223022461,
          4.37937068939209,
          4.395007610321045,
          4.404457092285156,
          4.311020851135254,
          3.825014352798462,
          3.591038227081299,
          4.2825026512146,
          4.592009544372559,
          3.7231125831604004,
          4.155919075012207,
          4.172382831573486,
          3.9989044666290283,
          4.094503402709961,
          4.2092719078063965,
          3.415410041809082,
          3.613262414932251,
          4.061995506286621,
          4.184964179992676,
          4.3409247398376465,
          4.017824649810791,
          4.002307415008545,
          4.185202121734619,
          3.7202658653259277,
          3.8485326766967773,
          4.061639308929443,
          4.366475582122803,
          3.6463987827301025,
          3.5640926361083984,
          3.8662238121032715,
          4.401735782623291,
          3.5886125564575195,
          3.3784122467041016,
          4.601628303527832,
          4.76814079284668,
          3.6365413665771484,
          3.2582006454467773,
          4.089982986450195,
          3.987532615661621,
          3.776599168777466,
          3.620972156524658,
          3.831416368484497,
          3.696591377258301,
          3.361966371536255,
          3.304288625717163,
          3.723445177078247,
          3.5253570079803467,
          3.599006414413452,
          4.474743843078613,
          4.251072406768799,
          3.12809681892395,
          4.937796592712402,
          4.653276443481445,
          4.678230285644531,
          4.7869648933410645,
          3.5010335445404053,
          3.510896921157837,
          4.7730913162231445,
          3.4411399364471436,
          5.164831638336182,
          4.7355217933654785,
          4.737537384033203,
          4.370449542999268,
          4.175248146057129,
          4.004130840301514,
          4.324367523193359,
          3.525918960571289,
          3.6124062538146973,
          4.026073455810547,
          4.832849025726318,
          4.7411017417907715,
          3.8878650665283203,
          4.247345924377441,
          5.540732383728027,
          4.237248420715332,
          4.744450569152832,
          3.573474168777466,
          5.084744930267334,
          4.657597541809082,
          3.871762275695801,
          4.921644687652588,
          4.322505950927734,
          4.085502624511719,
          4.660088539123535,
          4.367764949798584,
          4.0316386222839355,
          4.173428535461426,
          3.8064048290252686,
          3.9222006797790527,
          3.4682915210723877,
          3.5281121730804443,
          4.738847732543945,
          4.369297027587891,
          3.988881826400757,
          3.53721284866333,
          4.308439254760742,
          4.03232479095459,
          4.394130706787109,
          4.3337554931640625,
          4.551822662353516,
          4.37848424911499,
          3.5327744483947754,
          3.7866127490997314,
          4.952121257781982,
          4.680802822113037,
          4.892543792724609,
          4.5181145668029785,
          5.669659614562988,
          5.687509059906006,
          3.627885103225708,
          3.853578567504883,
          3.915586471557617,
          3.9315297603607178,
          3.575078248977661,
          3.638735055923462,
          4.337241172790527,
          3.650468111038208,
          4.392159938812256,
          4.347739219665527,
          3.8472604751586914,
          3.9163312911987305,
          3.826805591583252,
          3.9010534286499023,
          4.8607072830200195,
          4.459071159362793,
          4.076404571533203,
          4.450062274932861,
          3.494168281555176,
          3.609501361846924,
          4.2527923583984375,
          4.589993953704834,
          4.375901222229004,
          4.202798366546631,
          3.4023473262786865,
          3.6641461849212646,
          3.5649044513702393,
          3.8238329887390137,
          3.702537775039673,
          3.653872489929199,
          3.905761241912842,
          3.660360813140869,
          4.3774590492248535,
          4.002474308013916,
          4.4320526123046875,
          4.178765296936035,
          3.2216851711273193,
          3.1774609088897705,
          4.122107028961182,
          3.724371910095215,
          3.8015496730804443,
          3.7449758052825928,
          3.8539178371429443,
          3.9818129539489746,
          4.624388217926025,
          4.365523338317871,
          3.6205410957336426,
          3.230433464050293,
          3.9466090202331543,
          3.522195816040039,
          4.232734203338623,
          4.311910152435303,
          3.6079185009002686,
          3.210394859313965,
          4.1230645179748535,
          3.6347291469573975,
          3.6176917552948,
          3.4502453804016113,
          3.8875956535339355,
          3.7556018829345703,
          4.120510101318359,
          4.469518184661865,
          3.5660600662231445,
          4.607252597808838,
          3.7684273719787598,
          4.256899356842041,
          4.292426109313965,
          4.783112525939941,
          3.370586633682251,
          4.137181758880615,
          4.904094696044922,
          5.053400039672852,
          4.255860805511475,
          4.201563835144043,
          3.8704826831817627,
          4.3270487785339355,
          3.724431037902832,
          3.3088762760162354,
          3.8735053539276123,
          4.390876770019531,
          3.7873899936676025,
          3.3365907669067383,
          4.124111175537109,
          3.6921417713165283,
          3.9791929721832275,
          3.851365566253662,
          3.91984486579895,
          4.177209377288818,
          3.862757921218872,
          4.098422527313232,
          4.01267147064209,
          4.166205883026123,
          3.6574323177337646,
          3.8967835903167725,
          4.43240213394165,
          4.028820037841797,
          4.409839630126953,
          4.744843006134033,
          3.1697781085968018,
          3.0105879306793213,
          3.6395986080169678,
          4.007118225097656,
          3.3914103507995605,
          3.5857555866241455,
          3.9091744422912598,
          4.832833290100098,
          3.6894304752349854,
          3.2575433254241943,
          3.431969404220581,
          3.6923913955688477,
          3.1749374866485596,
          3.0522031784057617
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"78e43c16-c83f-4bef-baac-fc36ef31e97f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"78e43c16-c83f-4bef-baac-fc36ef31e97f\")) {                    Plotly.newPlot(                        \"78e43c16-c83f-4bef-baac-fc36ef31e97f\",                        [{\"mode\": \"lines+markers\", \"type\": \"scatter\", \"y\": [0.07325822114944458, 0.046621911227703094, 0.06720030307769775, 0.16485078632831573, 0.12710250914096832, 0.1459663063287735, 0.12971051037311554, 0.15653082728385925, 0.198111891746521, 0.14898745715618134, 0.12907369434833527, 0.111030712723732, 0.16316737234592438, 0.1617959886789322, 0.33506932854652405, 0.12696446478366852, 0.1364874690771103, 0.08606074750423431, 0.12954524159431458, 0.1432657092809677, 0.0923694521188736, 0.1616511046886444, 0.21592757105827332, 0.3944830894470215, 0.5662891864776611, 0.8975823521614075, 0.6645099520683289, 0.9026135206222534, 1.3380711078643799, 1.61506986618042, 2.1740567684173584, 2.5584652423858643, 3.191880941390991, 3.4603757858276367, 3.9641401767730713, 4.193936824798584, 4.879309177398682, 5.407907009124756, 5.670400619506836, 5.927031993865967, 6.847367763519287, 7.207455158233643, 8.286916732788086, 8.62362003326416, 8.873421669006348, 7.410782337188721, 10.065760612487793, 8.366803169250488, 9.379404067993164, 8.752954483032227, 9.280055046081543, 9.739532470703125, 11.695544242858887, 11.016702651977539, 10.900053977966309, 12.411018371582031, 11.351550102233887, 11.979973793029785, 11.608773231506348, 10.273354530334473, 10.966498374938965, 11.530841827392578, 12.82982063293457, 12.024937629699707, 13.665803909301758, 13.68529224395752, 14.097813606262207, 14.870441436767578, 15.125972747802734, 14.886341094970703, 13.729607582092285, 13.267682075500488, 12.934028625488281, 13.424786567687988, 12.998279571533203, 13.198681831359863, 13.366549491882324, 14.31176471710205, 13.942516326904297, 13.679277420043945, 14.730884552001953, 14.938858985900879, 11.421335220336914, 12.473701477050781, 13.745439529418945, 13.37606430053711, 12.3412446975708, 11.926034927368164, 14.440260887145996, 13.307440757751465, 11.517152786254883, 10.369356155395508, 11.751615524291992, 11.568998336791992, 12.284360885620117, 11.970221519470215, 11.543891906738281, 10.261797904968262, 10.031187057495117, 10.475564002990723, 10.450770378112793, 9.316959381103516, 8.816927909851074, 8.786959648132324, 9.022683143615723, 8.910444259643555, 8.356245994567871, 8.667119979858398, 7.9119954109191895, 7.4927263259887695, 7.663361072540283, 7.793565273284912, 6.954769611358643, 6.4790263175964355, 8.73556137084961, 8.314706802368164, 8.168072700500488, 7.897907733917236, 7.395549297332764, 7.985322952270508, 7.10295295715332, 7.187770366668701, 8.743927001953125, 9.1899995803833, 9.105757713317871, 9.975050926208496, 9.63197135925293, 9.907820701599121, 8.85027027130127, 8.559206008911133, 8.57529067993164, 8.833267211914062, 8.729986190795898, 8.857508659362793, 8.39091682434082, 8.206887245178223, 9.3495512008667, 8.955519676208496, 9.104303359985352, 9.284830093383789, 9.826787948608398, 9.682920455932617, 9.878460884094238, 8.509788513183594, 8.631022453308105, 8.21363639831543, 9.33701229095459, 8.45040225982666, 9.089249610900879, 8.268509864807129, 7.5947184562683105, 6.929995059967041, 6.507326602935791, 6.862899303436279, 7.599410533905029, 7.450240612030029, 7.928675651550293, 8.027159690856934, 7.326937198638916, 8.095606803894043, 7.398421764373779, 6.357515811920166, 8.641571044921875, 9.217506408691406, 6.89894962310791, 5.703174114227295, 5.5876946449279785, 5.923852443695068, 6.276574611663818, 6.363499641418457, 7.113084316253662, 6.741958141326904, 7.518833160400391, 6.688551425933838, 6.661281108856201, 6.14520263671875, 5.610434532165527, 5.923949241638184, 7.198859214782715, 7.119760513305664, 6.75717306137085, 6.337278366088867, 6.2851104736328125, 6.263066291809082, 6.4748125076293945, 5.894382476806641, 5.84127140045166, 5.621703147888184, 5.437796592712402, 5.185561656951904, 5.692211627960205, 5.596507549285889, 6.151829719543457, 6.414225101470947, 5.537108421325684, 5.586088180541992, 6.750873565673828, 6.31066370010376, 5.3838791847229, 5.630784034729004, 5.298333168029785, 5.177587985992432, 5.469091892242432, 5.686617374420166, 5.053889751434326, 5.904087066650391, 5.684298992156982, 5.69293212890625, 5.140252113342285, 5.4160614013671875, 4.517979621887207, 4.734652996063232, 5.522044658660889, 5.715340614318848, 5.566802024841309, 5.618587017059326, 5.9890055656433105, 6.741981029510498, 5.762358665466309, 5.73344087600708, 6.240195274353027, 5.801384925842285, 4.79604959487915, 5.1581621170043945, 6.036635875701904, 5.406981468200684, 5.487913131713867, 5.047749996185303, 5.061098575592041, 5.308687210083008, 5.00323486328125, 4.865390300750732, 4.516645431518555, 4.245776653289795, 4.780021667480469, 4.518180847167969, 4.5894455909729, 4.550908088684082, 4.43669319152832, 4.401508331298828, 4.565305233001709, 5.0450053215026855, 4.57665491104126, 4.745485305786133, 5.940205097198486, 4.911580562591553, 4.733391761779785, 4.687233924865723, 4.810449600219727, 4.802178382873535, 5.698487758636475, 5.903448581695557, 4.534120082855225, 4.89021635055542, 4.866110324859619, 5.46573543548584, 5.2376909255981445, 5.548262596130371, 5.274167537689209, 4.354578495025635, 4.220457077026367, 3.7868494987487793, 5.395148754119873, 4.937014102935791, 4.9019389152526855, 5.744762897491455, 3.7664296627044678, 3.8691887855529785, 4.72027587890625, 4.18048620223999, 4.2144904136657715, 4.09060001373291, 4.7158660888671875, 4.383787631988525, 4.225195407867432, 4.083127498626709, 5.062377452850342, 3.9988927841186523, 6.04597282409668, 6.262594223022461, 4.37937068939209, 4.395007610321045, 4.404457092285156, 4.311020851135254, 3.825014352798462, 3.591038227081299, 4.2825026512146, 4.592009544372559, 3.7231125831604004, 4.155919075012207, 4.172382831573486, 3.9989044666290283, 4.094503402709961, 4.2092719078063965, 3.415410041809082, 3.613262414932251, 4.061995506286621, 4.184964179992676, 4.3409247398376465, 4.017824649810791, 4.002307415008545, 4.185202121734619, 3.7202658653259277, 3.8485326766967773, 4.061639308929443, 4.366475582122803, 3.6463987827301025, 3.5640926361083984, 3.8662238121032715, 4.401735782623291, 3.5886125564575195, 3.3784122467041016, 4.601628303527832, 4.76814079284668, 3.6365413665771484, 3.2582006454467773, 4.089982986450195, 3.987532615661621, 3.776599168777466, 3.620972156524658, 3.831416368484497, 3.696591377258301, 3.361966371536255, 3.304288625717163, 3.723445177078247, 3.5253570079803467, 3.599006414413452, 4.474743843078613, 4.251072406768799, 3.12809681892395, 4.937796592712402, 4.653276443481445, 4.678230285644531, 4.7869648933410645, 3.5010335445404053, 3.510896921157837, 4.7730913162231445, 3.4411399364471436, 5.164831638336182, 4.7355217933654785, 4.737537384033203, 4.370449542999268, 4.175248146057129, 4.004130840301514, 4.324367523193359, 3.525918960571289, 3.6124062538146973, 4.026073455810547, 4.832849025726318, 4.7411017417907715, 3.8878650665283203, 4.247345924377441, 5.540732383728027, 4.237248420715332, 4.744450569152832, 3.573474168777466, 5.084744930267334, 4.657597541809082, 3.871762275695801, 4.921644687652588, 4.322505950927734, 4.085502624511719, 4.660088539123535, 4.367764949798584, 4.0316386222839355, 4.173428535461426, 3.8064048290252686, 3.9222006797790527, 3.4682915210723877, 3.5281121730804443, 4.738847732543945, 4.369297027587891, 3.988881826400757, 3.53721284866333, 4.308439254760742, 4.03232479095459, 4.394130706787109, 4.3337554931640625, 4.551822662353516, 4.37848424911499, 3.5327744483947754, 3.7866127490997314, 4.952121257781982, 4.680802822113037, 4.892543792724609, 4.5181145668029785, 5.669659614562988, 5.687509059906006, 3.627885103225708, 3.853578567504883, 3.915586471557617, 3.9315297603607178, 3.575078248977661, 3.638735055923462, 4.337241172790527, 3.650468111038208, 4.392159938812256, 4.347739219665527, 3.8472604751586914, 3.9163312911987305, 3.826805591583252, 3.9010534286499023, 4.8607072830200195, 4.459071159362793, 4.076404571533203, 4.450062274932861, 3.494168281555176, 3.609501361846924, 4.2527923583984375, 4.589993953704834, 4.375901222229004, 4.202798366546631, 3.4023473262786865, 3.6641461849212646, 3.5649044513702393, 3.8238329887390137, 3.702537775039673, 3.653872489929199, 3.905761241912842, 3.660360813140869, 4.3774590492248535, 4.002474308013916, 4.4320526123046875, 4.178765296936035, 3.2216851711273193, 3.1774609088897705, 4.122107028961182, 3.724371910095215, 3.8015496730804443, 3.7449758052825928, 3.8539178371429443, 3.9818129539489746, 4.624388217926025, 4.365523338317871, 3.6205410957336426, 3.230433464050293, 3.9466090202331543, 3.522195816040039, 4.232734203338623, 4.311910152435303, 3.6079185009002686, 3.210394859313965, 4.1230645179748535, 3.6347291469573975, 3.6176917552948, 3.4502453804016113, 3.8875956535339355, 3.7556018829345703, 4.120510101318359, 4.469518184661865, 3.5660600662231445, 4.607252597808838, 3.7684273719787598, 4.256899356842041, 4.292426109313965, 4.783112525939941, 3.370586633682251, 4.137181758880615, 4.904094696044922, 5.053400039672852, 4.255860805511475, 4.201563835144043, 3.8704826831817627, 4.3270487785339355, 3.724431037902832, 3.3088762760162354, 3.8735053539276123, 4.390876770019531, 3.7873899936676025, 3.3365907669067383, 4.124111175537109, 3.6921417713165283, 3.9791929721832275, 3.851365566253662, 3.91984486579895, 4.177209377288818, 3.862757921218872, 4.098422527313232, 4.01267147064209, 4.166205883026123, 3.6574323177337646, 3.8967835903167725, 4.43240213394165, 4.028820037841797, 4.409839630126953, 4.744843006134033, 3.1697781085968018, 3.0105879306793213, 3.6395986080169678, 4.007118225097656, 3.3914103507995605, 3.5857555866241455, 3.9091744422912598, 4.832833290100098, 3.6894304752349854, 3.2575433254241943, 3.431969404220581, 3.6923913955688477, 3.1749374866485596, 3.0522031784057617]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('78e43c16-c83f-4bef-baac-fc36ef31e97f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_faulty_dataset = Dataset(path='.\\\\data\\\\training.h5', key='faulty', simulation=(1, 1))\n",
    "\n",
    "mse_faulty = []\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for data in train_faulty_dataset:\n",
    "    X = data['X'].to(device)\n",
    "    output = model(X)\n",
    "    mse_faulty.append(criterion(output, X).item())\n",
    "    \n",
    "fig = go.Figure(data=go.Scatter(y=mse_faulty, mode='lines+markers'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-forth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
